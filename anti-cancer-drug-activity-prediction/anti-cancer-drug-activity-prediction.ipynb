{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These is a classification problem** to develop a predictive model that can accurately predict the anti-cancer activity of a set of drug compounds, based on their molecular structures.. The performance of the model will be evaluated using various metrics, including accuracy, precision, recall, and F1 score. </br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input** is a dataset of drug compounds represented by their molecular structures. The dataset consists of around 4,000 drug compounds and their corresponding activity levels, measured using a bioassay..</br>\n",
    "**The output** the label represent if the chemical compound is positive against non-small cell lung cancer, or negative:\n",
    "* 1 for possitive\n",
    "* 0 for negative.</br>\n",
    "\n",
    "**The goal** is to develop a predictive model that can take in the molecular graph representations of the drug compounds and predict their activity levels against cancer cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The challenges** \n",
    "1. Data sparsity and imbalance: The dataset of drug compounds and their activity levels may be sparse, meaning that there is a limited amount of data available for training and testing the predictive model. Additionally, the dataset may be imbalanced, meaning that there are significantly more compounds of one activity level than the other. This can make it difficult to train a predictive model that is both accurate and generalizes well to new data.\n",
    "\n",
    "2. Complex molecular structures: Drug compounds can have complex molecular structures that require specialized methods for feature extraction and representation. The molecular structures may also contain noise or errors, which can affect the performance of the predictive model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The impact of predictive models for anti-cancer drug activity prediction can be significant in several ways:**\n",
    "1. Accelerating drug discovery: Predictive models can help identify drug compounds with high activity levels against cancer cells more quickly and efficiently than traditional experimental methods. This can accelerate the drug discovery process and reduce the cost and time required to develop new anti-cancer drugs.\n",
    "\n",
    "2. Improving drug efficacy and safety: Predictive models can help identify drug compounds with higher efficacy and safety profiles, reducing the risk of adverse side effects and improving patient outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Get Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:43:48.585035Z",
     "iopub.status.busy": "2023-04-28T14:43:48.584556Z",
     "iopub.status.idle": "2023-04-28T14:43:49.580757Z",
     "shell.execute_reply": "2023-04-28T14:43:49.579237Z",
     "shell.execute_reply.started": "2023-04-28T14:43:48.584994Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import math\n",
    "sns.set()\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:43:49.583889Z",
     "iopub.status.busy": "2023-04-28T14:43:49.583500Z",
     "iopub.status.idle": "2023-04-28T14:44:28.422846Z",
     "shell.execute_reply": "2023-04-28T14:44:28.421522Z",
     "shell.execute_reply.started": "2023-04-28T14:43:49.583851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.83.0 which is incompatible.\n",
      "onnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
      "apache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet tf2_gnn\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "\n",
    "from tf2_gnn.layers.gnn import GNN, GNNInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:28.425132Z",
     "iopub.status.busy": "2023-04-28T14:44:28.424453Z",
     "iopub.status.idle": "2023-04-28T14:44:28.432091Z",
     "shell.execute_reply": "2023-04-28T14:44:28.431103Z",
     "shell.execute_reply.started": "2023-04-28T14:44:28.425092Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:28.435016Z",
     "iopub.status.busy": "2023-04-28T14:44:28.434366Z",
     "iopub.status.idle": "2023-04-28T14:44:28.451070Z",
     "shell.execute_reply": "2023-04-28T14:44:28.449816Z",
     "shell.execute_reply.started": "2023-04-28T14:44:28.434978Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import resample \n",
    "import tensorflow as tf\n",
    "from tensorflow.math import segment_mean\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:28.453270Z",
     "iopub.status.busy": "2023-04-28T14:44:28.452747Z",
     "iopub.status.idle": "2023-04-28T14:44:28.461708Z",
     "shell.execute_reply": "2023-04-28T14:44:28.460691Z",
     "shell.execute_reply.started": "2023-04-28T14:44:28.453224Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten, Dropout\n",
    "from tensorflow.keras.layers import GRU, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:28.463835Z",
     "iopub.status.busy": "2023-04-28T14:44:28.463291Z",
     "iopub.status.idle": "2023-04-28T14:44:40.423130Z",
     "shell.execute_reply": "2023-04-28T14:44:40.421591Z",
     "shell.execute_reply.started": "2023-04-28T14:44:28.463795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install --quiet tf2_gnn\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "\n",
    "from tf2_gnn.layers.gnn import GNN, GNNInput\n",
    "from tf2_gnn.layers.message_passing import GNN_Edge_MLP, GNN_FiLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:40.425432Z",
     "iopub.status.busy": "2023-04-28T14:44:40.425053Z",
     "iopub.status.idle": "2023-04-28T14:44:40.431470Z",
     "shell.execute_reply": "2023-04-28T14:44:40.430185Z",
     "shell.execute_reply.started": "2023-04-28T14:44:40.425396Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:40.433505Z",
     "iopub.status.busy": "2023-04-28T14:44:40.433145Z",
     "iopub.status.idle": "2023-04-28T14:44:52.110110Z",
     "shell.execute_reply": "2023-04-28T14:44:52.108366Z",
     "shell.execute_reply.started": "2023-04-28T14:44:40.433473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:52.112755Z",
     "iopub.status.busy": "2023-04-28T14:44:52.112192Z",
     "iopub.status.idle": "2023-04-28T14:44:52.120189Z",
     "shell.execute_reply": "2023-04-28T14:44:52.118231Z",
     "shell.execute_reply.started": "2023-04-28T14:44:52.112697Z"
    }
   },
   "outputs": [],
   "source": [
    "from tf2_gnn.layers.gnn import GNN\n",
    "from tf2_gnn.layers.gnn import GNNInput\n",
    "from tf2_gnn.layers.message_passing import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:52.125100Z",
     "iopub.status.busy": "2023-04-28T14:44:52.124725Z",
     "iopub.status.idle": "2023-04-28T14:44:52.136939Z",
     "shell.execute_reply": "2023-04-28T14:44:52.135819Z",
     "shell.execute_reply.started": "2023-04-28T14:44:52.125067Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import segment_mean\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:52.138729Z",
     "iopub.status.busy": "2023-04-28T14:44:52.138375Z",
     "iopub.status.idle": "2023-04-28T14:44:52.153833Z",
     "shell.execute_reply": "2023-04-28T14:44:52.152470Z",
     "shell.execute_reply.started": "2023-04-28T14:44:52.138696Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tf2_gnn.layers.gnn import GNN, GNNInput\n",
    "# from tf2_gnn.utils.gnn import segment_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:52.156095Z",
     "iopub.status.busy": "2023-04-28T14:44:52.155650Z",
     "iopub.status.idle": "2023-04-28T14:44:52.166737Z",
     "shell.execute_reply": "2023-04-28T14:44:52.165845Z",
     "shell.execute_reply.started": "2023-04-28T14:44:52.156056Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# some seeting for pandas and hvplot\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 300\n",
    "pd.options.display.max_colwidth = 100\n",
    "np.set_printoptions(threshold=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SDF format data (structured-data format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:52.168107Z",
     "iopub.status.busy": "2023-04-28T14:44:52.167772Z",
     "iopub.status.idle": "2023-04-28T14:44:52.182336Z",
     "shell.execute_reply": "2023-04-28T14:44:52.180980Z",
     "shell.execute_reply.started": "2023-04-28T14:44:52.168076Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def read_sdf(file):\n",
    "    with open(file, 'r') as rf:\n",
    "        content = rf.read()\n",
    "    samples = content.split('$$$$')\n",
    "    \n",
    "    def parse_sample(s):\n",
    "        lines = s.splitlines()\n",
    "        links = []\n",
    "        nodes = []\n",
    "        label = 0\n",
    "        for l in lines:\n",
    "            if l.strip() == '1.0':\n",
    "                label = 1\n",
    "            if l.strip() == '-1.0':\n",
    "                label = 0\n",
    "            if l.startswith('    '):\n",
    "                feature = l.split()\n",
    "                node = feature[3]\n",
    "                nodes.append(node)\n",
    "            elif l.startswith(' '):\n",
    "                lnk = l.split()\n",
    "                # edge: (from, to,) (1-based index)\n",
    "                if int(lnk[0]) - 1 < len(nodes):\n",
    "                    links.append((\n",
    "                        int(lnk[0])-1, \n",
    "                        int(lnk[1])-1, # zero-based index\n",
    "                        # int(lnk[2]) ignore edge weight\n",
    "                    ))\n",
    "        return nodes, np.array(links), label\n",
    "    \n",
    "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:52.185374Z",
     "iopub.status.busy": "2023-04-28T14:44:52.184911Z",
     "iopub.status.idle": "2023-04-28T14:44:55.391505Z",
     "shell.execute_reply": "2023-04-28T14:44:55.390296Z",
     "shell.execute_reply.started": "2023-04-28T14:44:52.185324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4cc45eea164ba5bde71d31ba270526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_set = read_sdf('/kaggle/input/cisc873-dm-w23-a6/train.sdf')\n",
    "# training_set, validation_set = train_test_split(training_set, test_size=0.15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:55.393079Z",
     "iopub.status.busy": "2023-04-28T14:44:55.392763Z",
     "iopub.status.idle": "2023-04-28T14:44:56.949691Z",
     "shell.execute_reply": "2023-04-28T14:44:56.948421Z",
     "shell.execute_reply.started": "2023-04-28T14:44:55.393049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaf1c405a8a4208a3315cfc893af1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_set  = read_sdf('/kaggle/input/cisc873-dm-w23-a6/test_x.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:56.952307Z",
     "iopub.status.busy": "2023-04-28T14:44:56.951689Z",
     "iopub.status.idle": "2023-04-28T14:44:56.959735Z",
     "shell.execute_reply": "2023-04-28T14:44:56.958532Z",
     "shell.execute_reply.started": "2023-04-28T14:44:56.952257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['O', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  6],\n",
      "       [ 0, 15],\n",
      "       [ 1, 15],\n",
      "       [ 2,  7],\n",
      "       [ 3,  8],\n",
      "       [ 4,  7],\n",
      "       [ 5,  8],\n",
      "       [ 6,  9],\n",
      "       [ 7, 16],\n",
      "       [ 8, 17],\n",
      "       [ 9, 10],\n",
      "       [ 9, 11],\n",
      "       [10, 12],\n",
      "       [10, 22],\n",
      "       [11, 13],\n",
      "       [11, 23],\n",
      "       [12, 21],\n",
      "       [12, 25],\n",
      "       [13, 20],\n",
      "       [13, 26],\n",
      "       [14, 15],\n",
      "       [14, 18],\n",
      "       [14, 19],\n",
      "       [16, 19],\n",
      "       [16, 24],\n",
      "       [17, 18],\n",
      "       [17, 24],\n",
      "       [20, 21],\n",
      "       [22, 27],\n",
      "       [23, 28],\n",
      "       [25, 29],\n",
      "       [26, 30],\n",
      "       [27, 29],\n",
      "       [28, 30]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(training_set[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing/Inspecting a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T09:59:13.027754Z",
     "iopub.status.busy": "2023-04-20T09:59:13.026904Z",
     "iopub.status.idle": "2023-04-20T09:59:13.036417Z",
     "shell.execute_reply": "2023-04-20T09:59:13.035398Z",
     "shell.execute_reply.started": "2023-04-20T09:59:13.027695Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T09:59:13.039368Z",
     "iopub.status.busy": "2023-04-20T09:59:13.038508Z",
     "iopub.status.idle": "2023-04-20T09:59:13.048979Z",
     "shell.execute_reply": "2023-04-20T09:59:13.047569Z",
     "shell.execute_reply.started": "2023-04-20T09:59:13.039316Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(sample):\n",
    "    G=nx.Graph()\n",
    "    nodes = sample[0]\n",
    "    edges = sample[1]\n",
    "    \n",
    "    labeldict={}\n",
    "    node_color=[]\n",
    "    for i,n in enumerate(nodes):\n",
    "        G.add_node(i)\n",
    "        labeldict[i]=n\n",
    "        node_color.append(colors[hash(n)%len(colors)])\n",
    "\n",
    "    # a list of nodes:\n",
    "    for e in edges:\n",
    "        G.add_edge(e[0], e[1])\n",
    "        \n",
    "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
    "    plt.show()\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T09:59:13.051726Z",
     "iopub.status.busy": "2023-04-20T09:59:13.050910Z",
     "iopub.status.idle": "2023-04-20T09:59:13.334497Z",
     "shell.execute_reply": "2023-04-20T09:59:13.333336Z",
     "shell.execute_reply.started": "2023-04-20T09:59:13.051684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7c76df8a00d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.clf()\n",
    "visualize(training_set[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data Up-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:56.962394Z",
     "iopub.status.busy": "2023-04-28T14:44:56.961477Z",
     "iopub.status.idle": "2023-04-28T14:44:57.055924Z",
     "shell.execute_reply": "2023-04-28T14:44:57.054701Z",
     "shell.execute_reply.started": "2023-04-28T14:44:56.962343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    23806\n",
      "1     1218\n",
      "Name: label, dtype: int64\n",
      "1    23806\n",
      "0    23806\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "np.unique(np.array(training_set)[:,2],return_counts=True)\n",
    "train_df = pd.DataFrame(training_set, columns=['node','edge','label']) # convert train into DataFrame\n",
    "\n",
    "# print the count of 0,1 in the label column\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "\n",
    "class_0 = train_df[train_df['label'] == 0] # get all data that belong to negative class (label = 0) \n",
    "class_1 = train_df[train_df['label'] == 1] # get all data that belong to possitive class (label = 1) \n",
    "\n",
    "class_1 = resample(class_1, replace=True, n_samples=len(class_0), random_state=42)  # resample class_1\n",
    "upsampled_data = pd.concat([class_1, class_0])  # get upsampled data\n",
    "\n",
    "\n",
    "# print the count of 0,1 in the label column after data up-sampling\n",
    "print(upsampled_data[\"label\"].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.057557Z",
     "iopub.status.busy": "2023-04-28T14:44:57.057225Z",
     "iopub.status.idle": "2023-04-28T14:44:57.067977Z",
     "shell.execute_reply": "2023-04-28T14:44:57.066882Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.057524Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert upsampled_data from DataFram to an array \n",
    "data_upsampled = upsampled_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.069783Z",
     "iopub.status.busy": "2023-04-28T14:44:57.069388Z",
     "iopub.status.idle": "2023-04-28T14:44:57.086327Z",
     "shell.execute_reply": "2023-04-28T14:44:57.084917Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.069748Z"
    }
   },
   "outputs": [],
   "source": [
    "training_set, validation_set = train_test_split(data_upsampled, test_size=0.15,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the graph representation of a molecule as input to a machine learning model, we need to convert it into a numerical format that the model can process. This requires using a tokenizer, which maps the nodes and links in the graph representation to a set of unique numerical tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.088321Z",
     "iopub.status.busy": "2023-04-28T14:44:57.087846Z",
     "iopub.status.idle": "2023-04-28T14:44:57.681047Z",
     "shell.execute_reply": "2023-04-28T14:44:57.679624Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.088287Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_vocab = 500\n",
    "max_len = 100\n",
    "\n",
    "\n",
    "# build vocabulary from training set\n",
    "all_nodes = [s[0] for s in training_set]\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "tokenizer.fit_on_texts(all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.683661Z",
     "iopub.status.busy": "2023-04-28T14:44:57.683040Z",
     "iopub.status.idle": "2023-04-28T14:44:57.695952Z",
     "shell.execute_reply": "2023-04-28T14:44:57.694942Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.683582Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "def prepare_single_batch(samples):\n",
    "    # Extracts the list of node labels for each molecule from the samples list \n",
    "    sample_nodes = [s[0] for s in samples]\n",
    "    # Convert each node label in the sample_nodes list to a numeric token. \n",
    "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
    "    \n",
    "    # the pad_sequences function is used to pad the sample_nodes list,to a fixed length. By setting padding='post',\n",
    "    # the function adds padding zeros to the end of each sequence, so that all sequences have the same length.\n",
    "    sample_nodes = pad_sequences(sample_nodes, padding='post')\n",
    "    max_nodes_len = np.shape(sample_nodes)[1]\n",
    "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
    "    edges = [e for e in edges if len(e) > 0]\n",
    "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
    "    \n",
    "    all_nodes = np.reshape(sample_nodes, -1)\n",
    "    all_edges = np.concatenate(edges)\n",
    "\n",
    "    node_to_graph = np.reshape(node_to_graph, -1)\n",
    "    return {\n",
    "        'data': all_nodes,\n",
    "        'edges': all_edges,\n",
    "        'node2grah': node_to_graph,\n",
    "    }, np.array([s[2] for s in samples])\n",
    "\n",
    "\n",
    "\n",
    "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
    "    while True:\n",
    "        dataset = list(dataset)\n",
    "        if shuffle:\n",
    "            random.shuffle(dataset)\n",
    "        l = len(dataset)\n",
    "        for ndx in range(0, l, batch_size):\n",
    "            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
    "            yield prepare_single_batch(batch_samples)\n",
    "        if not repeat:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### showing one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.698321Z",
     "iopub.status.busy": "2023-04-28T14:44:57.697610Z",
     "iopub.status.idle": "2023-04-28T14:44:57.779171Z",
     "shell.execute_reply": "2023-04-28T14:44:57.777503Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.698284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "[ 4  3  3  3  3  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0\n",
      "  0  7  7  4  3  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  0 14  5  5  5  5  3  3  3  3  3  3  3  3  3  3  1  1  1  1  1  1  1\n",
      "  1  1  1  4  4  3  3  3  3  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "edges\n",
      "[[ 0  7]\n",
      " [ 1  2]\n",
      " [ 1  6]\n",
      " [ 2  7]\n",
      " [ 3  5]\n",
      " [ 3  9]\n",
      " [ 4  7]\n",
      " [ 4 13]\n",
      " [ 4 14]\n",
      " [ 5  6]\n",
      " [ 5  8]\n",
      " [ 6 11]\n",
      " [ 8 10]\n",
      " [ 9 12]\n",
      " [10 12]\n",
      " [25 38]\n",
      " [26 46]\n",
      " [27 35]\n",
      " [27 44]\n",
      " [28 32]\n",
      " [28 34]\n",
      " [29 33]\n",
      " [29 34]\n",
      " [30 32]\n",
      " [30 39]\n",
      " [31 32]\n",
      " [31 33]\n",
      " [31 36]\n",
      " [33 37]\n",
      " [34 35]\n",
      " [35 41]\n",
      " [36 38]\n",
      " [37 40]\n",
      " [38 40]\n",
      " [39 42]\n",
      " [39 43]\n",
      " [41 45]\n",
      " [42 46]\n",
      " [43 47]\n",
      " [44 45]\n",
      " [46 48]\n",
      " [47 48]\n",
      " [50 51]\n",
      " [50 52]\n",
      " [50 53]\n",
      " [50 54]\n",
      " [50 55]\n",
      " [50 56]\n",
      " [55 65]\n",
      " [55 67]\n",
      " [56 66]\n",
      " [56 68]\n",
      " [57 67]\n",
      " [57 71]\n",
      " [58 68]\n",
      " [58 72]\n",
      " [59 65]\n",
      " [60 66]\n",
      " [61 70]\n",
      " [61 74]\n",
      " [62 69]\n",
      " [62 73]\n",
      " [63 71]\n",
      " [63 73]\n",
      " [64 72]\n",
      " [64 74]\n",
      " [65 69]\n",
      " [66 70]\n",
      " [69 71]\n",
      " [70 72]\n",
      " [75 82]\n",
      " [75 83]\n",
      " [76 81]\n",
      " [76 84]\n",
      " [77 78]\n",
      " [77 82]\n",
      " [78 81]\n",
      " [79 80]\n",
      " [79 82]\n",
      " [80 81]]\n",
      "node2grah\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "label [1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for train_batch in gen_batch(training_set, batch_size=4):\n",
    "    for k,v in train_batch[0].items():\n",
    "        print(k)\n",
    "        print(v)\n",
    "        pass\n",
    "    print('label', train_batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.780680Z",
     "iopub.status.busy": "2023-04-28T14:44:57.780346Z",
     "iopub.status.idle": "2023-04-28T14:44:57.788517Z",
     "shell.execute_reply": "2023-04-28T14:44:57.787199Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.780625Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_model(model, training_set, validation_set, batch_size=16, num_epochs=5):\n",
    "    # calculate steps_per_epoch for training and validation data\n",
    "    num_batches = math.ceil(len(training_set) / batch_size)\n",
    "    num_batches_validation = math.ceil(len(validation_set) / batch_size)\n",
    "\n",
    "    # train the model\n",
    "    model.fit(\n",
    "        gen_batch(training_set, batch_size=batch_size, repeat=True),\n",
    "        steps_per_epoch=num_batches,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=gen_batch(validation_set, batch_size=batch_size, repeat=True),\n",
    "        validation_steps=num_batches_validation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.790737Z",
     "iopub.status.busy": "2023-04-28T14:44:57.790336Z",
     "iopub.status.idle": "2023-04-28T14:44:57.806283Z",
     "shell.execute_reply": "2023-04-28T14:44:57.804783Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.790682Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, testing_set, batch_size=16):\n",
    "    y_pred = model.predict(gen_batch(testing_set, batch_size=batch_size, shuffle=False))\n",
    "    y_pred = np.reshape(y_pred, -1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.808824Z",
     "iopub.status.busy": "2023-04-28T14:44:57.808277Z",
     "iopub.status.idle": "2023-04-28T14:44:57.819244Z",
     "shell.execute_reply": "2023-04-28T14:44:57.817981Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.808782Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_predictions_to_csv(y_pred, file_name):\n",
    "    submission = pd.DataFrame({'label': y_pred})\n",
    "    submission.index.name = 'id'\n",
    "    submission.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :**  Training data set without upsampling\n",
    "\n",
    "**The Model Used is :**\n",
    "The model uses a **single GNN layer** with dfault hyperparameters. The output of the GNN layer is passed through a function called **segment_mean**, which computes the mean of the node embeddings for each graph in the batch. This is intended to summarize the information from the nodes into a single vector per graph, which can be used for the prediction task.\n",
    "\n",
    "The output of the segment_mean function is passed through a **dense layer** with a **sigmoid** activation function to produce the final predictions. The model is compiled using the **binary cross-entropy loss** function and the **Adam optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T07:29:11.841029Z",
     "iopub.status.busy": "2023-04-28T07:29:11.840307Z",
     "iopub.status.idle": "2023-04-28T07:29:12.488339Z",
     "shell.execute_reply": "2023-04-28T07:29:12.487659Z",
     "shell.execute_reply.started": "2023-04-28T07:29:11.840985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_6/StatefulPartitionedCall:0', description=\"created by layer 'gnn_6'\")\n",
      "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_3/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_3'\")\n",
      "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_6/Sigmoid:0', description=\"created by layer 'dense_6'\")\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_4 (TFOpLamb  ()                  0           ['input_19[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 20)           10000       ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  ()                  0           ['tf.math.reduce_max_4[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_6 (GNN)                    (None, 32)           22464       ['embedding_4[0][0]',            \n",
      "                                                                  'input_18[0][0]',               \n",
      "                                                                  'input_19[0][0]',               \n",
      "                                                                  'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.segment_mean_3 (TFOpLa  (None, 32)          0           ['gnn_6[0][0]',                  \n",
      " mbda)                                                            'input_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            33          ['tf.math.segment_mean_3[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,497\n",
      "Trainable params: 32,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 32\n",
    "gnn_layer = GNN(params)\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    ")\n",
    "print('mean:', avg)\n",
    "\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "print('pred:', pred)\n",
    "\n",
    "modelV1 = Model(\n",
    "    inputs={\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "modelV1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T07:29:12.490326Z",
     "iopub.status.busy": "2023-04-28T07:29:12.489995Z",
     "iopub.status.idle": "2023-04-28T07:29:12.508626Z",
     "shell.execute_reply": "2023-04-28T07:29:12.507522Z",
     "shell.execute_reply.started": "2023-04-28T07:29:12.490293Z"
    }
   },
   "outputs": [],
   "source": [
    "modelV1.compile(\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T07:29:12.791581Z",
     "iopub.status.busy": "2023-04-28T07:29:12.791096Z",
     "iopub.status.idle": "2023-04-28T07:39:42.593378Z",
     "shell.execute_reply": "2023-04-28T07:39:42.592261Z",
     "shell.execute_reply.started": "2023-04-28T07:29:12.791526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1564/1564 [==============================] - 26s 15ms/step - loss: 0.2262 - auc: 0.5049 - val_loss: 1.5427 - val_auc: 0.5924\n",
      "Epoch 2/25\n",
      "1564/1564 [==============================] - 24s 15ms/step - loss: 0.1938 - auc: 0.6208 - val_loss: 1.3460 - val_auc: 0.6433\n",
      "Epoch 3/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1902 - auc: 0.6347 - val_loss: 1.6925 - val_auc: 0.6456\n",
      "Epoch 4/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1880 - auc: 0.6591 - val_loss: 1.5467 - val_auc: 0.6749\n",
      "Epoch 5/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1862 - auc: 0.6674 - val_loss: 1.4406 - val_auc: 0.6887\n",
      "Epoch 6/25\n",
      "1564/1564 [==============================] - 23s 14ms/step - loss: 0.1849 - auc: 0.6752 - val_loss: 1.5824 - val_auc: 0.6693\n",
      "Epoch 7/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1837 - auc: 0.6762 - val_loss: 1.2808 - val_auc: 0.7015\n",
      "Epoch 8/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1832 - auc: 0.6877 - val_loss: 1.2712 - val_auc: 0.7192\n",
      "Epoch 9/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1793 - auc: 0.7124 - val_loss: 1.3274 - val_auc: 0.7358\n",
      "Epoch 10/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1800 - auc: 0.7138 - val_loss: 1.2431 - val_auc: 0.7207\n",
      "Epoch 11/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1786 - auc: 0.7205 - val_loss: 1.0963 - val_auc: 0.7521\n",
      "Epoch 12/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1780 - auc: 0.7244 - val_loss: 1.5399 - val_auc: 0.7368\n",
      "Epoch 13/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1793 - auc: 0.7194 - val_loss: 1.8440 - val_auc: 0.7034\n",
      "Epoch 14/25\n",
      "1564/1564 [==============================] - 23s 14ms/step - loss: 0.1798 - auc: 0.7152 - val_loss: 1.3815 - val_auc: 0.7434\n",
      "Epoch 15/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1807 - auc: 0.7207 - val_loss: 1.3682 - val_auc: 0.7382\n",
      "Epoch 16/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1787 - auc: 0.7224 - val_loss: 1.6166 - val_auc: 0.7315\n",
      "Epoch 17/25\n",
      "1564/1564 [==============================] - 23s 14ms/step - loss: 0.1785 - auc: 0.7244 - val_loss: 1.5284 - val_auc: 0.7182\n",
      "Epoch 18/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1795 - auc: 0.7175 - val_loss: 1.7196 - val_auc: 0.6741\n",
      "Epoch 19/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1788 - auc: 0.7289 - val_loss: 1.1283 - val_auc: 0.7446\n",
      "Epoch 20/25\n",
      "1564/1564 [==============================] - 23s 14ms/step - loss: 0.1787 - auc: 0.7192 - val_loss: 1.5850 - val_auc: 0.7218\n",
      "Epoch 21/25\n",
      "1564/1564 [==============================] - 24s 15ms/step - loss: 0.1787 - auc: 0.7205 - val_loss: 1.6006 - val_auc: 0.7163\n",
      "Epoch 22/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1800 - auc: 0.7126 - val_loss: 1.4866 - val_auc: 0.7236\n",
      "Epoch 23/25\n",
      "1564/1564 [==============================] - 23s 15ms/step - loss: 0.1793 - auc: 0.7191 - val_loss: 1.7551 - val_auc: 0.6919\n",
      "Epoch 24/25\n",
      "1564/1564 [==============================] - 25s 16ms/step - loss: 0.1796 - auc: 0.7122 - val_loss: 1.6180 - val_auc: 0.6935\n",
      "Epoch 25/25\n",
      "1564/1564 [==============================] - 22s 14ms/step - loss: 0.1793 - auc: 0.7132 - val_loss: 1.3156 - val_auc: 0.7420\n",
      "771/771 [==============================] - 5s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV1, training_set, validation_set, batch_size=16, num_epochs=25)\n",
    "y_pred = get_predictions(modelV1, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'First_Trial.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 71.32 %</br>\n",
    "**validatation accuracy (auc)**: 74.20 %</br>\n",
    "**Testing Accuracy (auc)**: 72.088 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "No overfitting happened here the test score is near to the validation score, maybe the increase in the model complexity of the model will be followed by an increase in performance , or use upsamling for training data set will help in increaseing the performance.</br>\n",
    "In the next trial we will try to use upsampling data with the same model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :** Same as the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T14:38:35.298153Z",
     "iopub.status.busy": "2023-04-26T14:38:35.297652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2530/2530 [==============================] - 51s 18ms/step - loss: 0.6394 - auc: 0.6834 - val_loss: 0.6178 - val_auc: 0.7288\n",
      "Epoch 2/25\n",
      "2530/2530 [==============================] - 48s 19ms/step - loss: 0.6013 - auc: 0.7390 - val_loss: 0.5833 - val_auc: 0.7596\n",
      "Epoch 3/25\n",
      "2530/2530 [==============================] - 49s 19ms/step - loss: 0.5782 - auc: 0.7645 - val_loss: 0.5688 - val_auc: 0.7829\n",
      "Epoch 4/25\n",
      "2530/2530 [==============================] - 49s 19ms/step - loss: 0.5619 - auc: 0.7814 - val_loss: 0.5484 - val_auc: 0.7992\n",
      "Epoch 5/25\n",
      "2530/2530 [==============================] - 46s 18ms/step - loss: 0.5456 - auc: 0.7980 - val_loss: 0.5217 - val_auc: 0.8230\n",
      "Epoch 6/25\n",
      "2530/2530 [==============================] - 46s 18ms/step - loss: 0.5350 - auc: 0.8081 - val_loss: 0.5066 - val_auc: 0.8371\n",
      "Epoch 7/25\n",
      "2530/2530 [==============================] - 48s 19ms/step - loss: 0.5246 - auc: 0.8179 - val_loss: 0.5100 - val_auc: 0.8328\n",
      "Epoch 8/25\n",
      "2530/2530 [==============================] - 47s 18ms/step - loss: 0.5165 - auc: 0.8251 - val_loss: 0.4894 - val_auc: 0.8472\n",
      "Epoch 9/25\n",
      "2530/2530 [==============================] - 46s 18ms/step - loss: 0.5094 - auc: 0.8309 - val_loss: 0.4928 - val_auc: 0.8452\n",
      "Epoch 10/25\n",
      "2530/2530 [==============================] - 48s 19ms/step - loss: 0.5054 - auc: 0.8347 - val_loss: 0.4844 - val_auc: 0.8537\n",
      "Epoch 11/25\n",
      "2530/2530 [==============================] - 48s 19ms/step - loss: 0.4978 - auc: 0.8401 - val_loss: 0.4933 - val_auc: 0.8493\n",
      "Epoch 12/25\n",
      "2530/2530 [==============================] - 48s 19ms/step - loss: 0.4902 - auc: 0.8451 - val_loss: 0.4803 - val_auc: 0.8540\n",
      "Epoch 13/25\n",
      "2530/2530 [==============================] - 46s 18ms/step - loss: 0.4863 - auc: 0.8486 - val_loss: 0.4595 - val_auc: 0.8655\n",
      "Epoch 14/25\n",
      "2530/2530 [==============================] - 46s 18ms/step - loss: 0.4816 - auc: 0.8511 - val_loss: 0.4802 - val_auc: 0.8624\n",
      "Epoch 15/25\n",
      "2530/2530 [==============================] - 47s 19ms/step - loss: 0.4799 - auc: 0.8535 - val_loss: 0.4566 - val_auc: 0.8683\n",
      "Epoch 16/25\n",
      "2530/2530 [==============================] - 49s 19ms/step - loss: 0.4741 - auc: 0.8567 - val_loss: 0.4534 - val_auc: 0.8713\n",
      "Epoch 17/25\n",
      "2530/2530 [==============================] - 49s 19ms/step - loss: 0.4712 - auc: 0.8590 - val_loss: 0.4968 - val_auc: 0.8601\n",
      "Epoch 18/25\n",
      "2530/2530 [==============================] - 51s 20ms/step - loss: 0.4721 - auc: 0.8587 - val_loss: 0.4465 - val_auc: 0.8753\n",
      "Epoch 19/25\n",
      "2530/2530 [==============================] - 48s 19ms/step - loss: 0.4662 - auc: 0.8621 - val_loss: 0.4624 - val_auc: 0.8715\n",
      "Epoch 20/25\n",
      "2530/2530 [==============================] - 50s 20ms/step - loss: 0.4637 - auc: 0.8640 - val_loss: 0.4591 - val_auc: 0.8778\n",
      "Epoch 21/25\n",
      "2530/2530 [==============================] - 47s 19ms/step - loss: 0.4589 - auc: 0.8667 - val_loss: 0.4773 - val_auc: 0.8716\n",
      "Epoch 22/25\n",
      "2530/2530 [==============================] - 46s 18ms/step - loss: 0.4604 - auc: 0.8664 - val_loss: 0.4322 - val_auc: 0.8863\n",
      "Epoch 23/25\n",
      "2530/2530 [==============================] - 47s 18ms/step - loss: 0.4583 - auc: 0.8673 - val_loss: 0.4351 - val_auc: 0.8825\n",
      "Epoch 24/25\n",
      "2530/2530 [==============================] - 46s 18ms/step - loss: 0.4548 - auc: 0.8695 - val_loss: 0.4551 - val_auc: 0.8756\n",
      "Epoch 25/25\n",
      "1877/2530 [=====================>........] - ETA: 11s - loss: 0.4526 - auc: 0.8706"
     ]
    }
   ],
   "source": [
    "train_model(modelV1, training_set, validation_set, batch_size=16, num_epochs=25)\n",
    "y_pred = get_predictions(modelV1, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Second_Trial.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 86.95 %</br>\n",
    "**validatation accuracy (auc)**: 87.56 %</br>\n",
    "**Testing Accuracy (auc)**: 80.78 %</br></br>\n",
    "\n",
    "**Comment:** </br>\n",
    "As we can see the performance increased when we used upsampling data so we will use upsampling data in the next trials.</br> \n",
    "Now we need to use different message passing method to find the best method with our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thired Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :**\n",
    "\n",
    "The model uses a **single GNN layer** with hyperparameters configured to use a **relational graph convolutional network** (RGCN) message passing method. The output of the GNN layer is passed through a function called **segment_mean**, which computes the mean of the node embeddings for each graph in the batch. This is intended to summarize the information from the nodes into a single vector per graph, which can be used for the prediction task.\n",
    "\n",
    "The output of the **segment_mean** function is passed through a dense layer with a sigmoid activation function to produce the final predictions. The model is compiled using **the binary cross-entropy loss** function and the **Adam optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T05:56:30.277197Z",
     "iopub.status.busy": "2023-04-28T05:56:30.276758Z",
     "iopub.status.idle": "2023-04-28T05:56:32.971428Z",
     "shell.execute_reply": "2023-04-28T05:56:32.968976Z",
     "shell.execute_reply.started": "2023-04-28T05:56:30.277155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_6[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 20)           10000       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " gnn (GNN)                      (None, 32)           22464       ['embedding[0][0]',              \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]',                \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
      " da)                                                              'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,497\n",
      "Trainable params: 32,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "# configure the hyperparameters of GNN layers\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "# \n",
    "# frist load the defualt hyperparameters\n",
    "params = GNN.get_default_hyperparameters()\n",
    "# sets the size of the output of all message passing layers\n",
    "params[\"hidden_dim\"] = 32\n",
    "# configures the message passing style to be RGCN (Relational Graph Convolutional Networks)\n",
    "params['message_calculation_class'] = 'RGCN'\n",
    "\n",
    "# Implements a deep Graph Neural Network\n",
    "gnn_layer = GNN(params)\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "\n",
    "\n",
    "# Computes the mean along segments of a tensor\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "avg = segment_mean(\n",
    "    data = gnn_out,\n",
    "    segment_ids = node2graph\n",
    ")\n",
    "\n",
    "# Define the output layer of the model\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "\n",
    "\n",
    "# Creating the model\n",
    "modelV3 = Model(\n",
    "    inputs = {\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs = pred\n",
    ")\n",
    "modelV3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T05:56:32.975738Z",
     "iopub.status.busy": "2023-04-28T05:56:32.974923Z",
     "iopub.status.idle": "2023-04-28T05:56:33.008269Z",
     "shell.execute_reply": "2023-04-28T05:56:33.007194Z",
     "shell.execute_reply.started": "2023-04-28T05:56:32.975684Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "modelV3.compile(\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T05:56:33.009985Z",
     "iopub.status.busy": "2023-04-28T05:56:33.009515Z",
     "iopub.status.idle": "2023-04-28T06:12:54.549068Z",
     "shell.execute_reply": "2023-04-28T06:12:54.546408Z",
     "shell.execute_reply.started": "2023-04-28T05:56:33.009938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2530/2530 [==============================] - 42s 15ms/step - loss: 0.6357 - auc: 0.6913 - val_loss: 0.6153 - val_auc: 0.7295\n",
      "Epoch 2/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.5960 - auc: 0.7451 - val_loss: 0.5785 - val_auc: 0.7691\n",
      "Epoch 3/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.5740 - auc: 0.7687 - val_loss: 0.5545 - val_auc: 0.7846\n",
      "Epoch 4/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.5593 - auc: 0.7853 - val_loss: 0.5554 - val_auc: 0.7927\n",
      "Epoch 5/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.5457 - auc: 0.7996 - val_loss: 0.5376 - val_auc: 0.8073\n",
      "Epoch 6/25\n",
      "2530/2530 [==============================] - 39s 16ms/step - loss: 0.5363 - auc: 0.8084 - val_loss: 0.5303 - val_auc: 0.8134\n",
      "Epoch 7/25\n",
      "2530/2530 [==============================] - 39s 16ms/step - loss: 0.5294 - auc: 0.8142 - val_loss: 0.5274 - val_auc: 0.8231\n",
      "Epoch 8/25\n",
      "2530/2530 [==============================] - 39s 16ms/step - loss: 0.5211 - auc: 0.8209 - val_loss: 0.5163 - val_auc: 0.8243\n",
      "Epoch 9/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.5122 - auc: 0.8294 - val_loss: 0.5010 - val_auc: 0.8387\n",
      "Epoch 10/25\n",
      "2530/2530 [==============================] - 39s 16ms/step - loss: 0.5073 - auc: 0.8336 - val_loss: 0.5047 - val_auc: 0.8366\n",
      "Epoch 11/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.5027 - auc: 0.8371 - val_loss: 0.4906 - val_auc: 0.8450\n",
      "Epoch 12/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4966 - auc: 0.8413 - val_loss: 0.4873 - val_auc: 0.8485\n",
      "Epoch 13/25\n",
      "2530/2530 [==============================] - 38s 15ms/step - loss: 0.4909 - auc: 0.8450 - val_loss: 0.4868 - val_auc: 0.8516\n",
      "Epoch 14/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4896 - auc: 0.8460 - val_loss: 0.4871 - val_auc: 0.8484\n",
      "Epoch 15/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4856 - auc: 0.8491 - val_loss: 0.4782 - val_auc: 0.8563\n",
      "Epoch 16/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4846 - auc: 0.8499 - val_loss: 0.4741 - val_auc: 0.8585\n",
      "Epoch 17/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4800 - auc: 0.8533 - val_loss: 0.4687 - val_auc: 0.8621\n",
      "Epoch 18/25\n",
      "2530/2530 [==============================] - 39s 16ms/step - loss: 0.4808 - auc: 0.8533 - val_loss: 0.4646 - val_auc: 0.8650\n",
      "Epoch 19/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4744 - auc: 0.8571 - val_loss: 0.4683 - val_auc: 0.8635\n",
      "Epoch 20/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4721 - auc: 0.8587 - val_loss: 0.4629 - val_auc: 0.8682\n",
      "Epoch 21/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4738 - auc: 0.8577 - val_loss: 0.4482 - val_auc: 0.8732\n",
      "Epoch 22/25\n",
      "2530/2530 [==============================] - 39s 15ms/step - loss: 0.4731 - auc: 0.8579 - val_loss: 0.4695 - val_auc: 0.8614\n",
      "Epoch 23/25\n",
      "2530/2530 [==============================] - 42s 16ms/step - loss: 0.4722 - auc: 0.8591 - val_loss: 0.4662 - val_auc: 0.8629\n",
      "Epoch 24/25\n",
      "2530/2530 [==============================] - 39s 16ms/step - loss: 0.4716 - auc: 0.8596 - val_loss: 0.4730 - val_auc: 0.8639\n",
      "Epoch 25/25\n",
      "2530/2530 [==============================] - 39s 16ms/step - loss: 0.4696 - auc: 0.8606 - val_loss: 0.4437 - val_auc: 0.8766\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/3030365983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave_predictions_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Third_Trial.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(modelV3, training_set, validation_set, batch_size=16, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T06:14:21.346146Z",
     "iopub.status.busy": "2023-04-28T06:14:21.345725Z",
     "iopub.status.idle": "2023-04-28T06:14:26.399857Z",
     "shell.execute_reply": "2023-04-28T06:14:26.398811Z",
     "shell.execute_reply.started": "2023-04-28T06:14:21.346111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 5s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV3, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Third_Trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 86.06 %</br>\n",
    "**validatation accuracy (auc)**: 87.66 %</br>\n",
    "**Testing Accuracy (auc)**: 81.03 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "when we used relational graph convolutional network (RGCN) message passing method the accuracy slightly increased.</br>\n",
    "So, we need to use different message passing method or use more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :**\n",
    "\n",
    "The model uses a **single GNN layer** with hyperparameters configured to use a **relational graph attention network** (RGAT) message passing method. The output of the GNN layer is passed through a function called **segment_mean**, which computes the **mean of the node** embeddings for each graph in the batch. This is intended to summarize the information from the nodes into a single vector per graph, which can be used for the prediction task.\n",
    "\n",
    "The output of the **segment_mean** function is passed through a dense layer with a **sigmoid** activation function to produce the final predictions. The model is compiled using the **binary cross-entropy loss** function and the **Adam optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T06:14:26.401986Z",
     "iopub.status.busy": "2023-04-28T06:14:26.401645Z",
     "iopub.status.idle": "2023-04-28T06:14:27.566333Z",
     "shell.execute_reply": "2023-04-28T06:14:27.564883Z",
     "shell.execute_reply.started": "2023-04-28T06:14:26.401955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 20)           10000       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_1 (GNN)                    (None, 32)           22720       ['embedding_1[0][0]',            \n",
      "                                                                  'input_8[0][0]',                \n",
      "                                                                  'input_9[0][0]',                \n",
      "                                                                  'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
      " mbda)                                                            'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            33          ['tf.math.segment_mean_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,753\n",
      "Trainable params: 32,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "# configure the hyperparameters of GNN layers\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "# \n",
    "# frist load the defualt hyperparameters\n",
    "params = GNN.get_default_hyperparameters()\n",
    "# sets the size of the output of all message passing layers\n",
    "params[\"hidden_dim\"] = 32\n",
    "# configures the message passing style to be RGAT (Relational Graph Attention Networks)\n",
    "params['message_calculation_class'] = 'RGAT'\n",
    "# configures the number of parallel (independent) weighted sums that are computed, whose results are concatenated to obtain the final result.\n",
    "params[\"num_heads\"] = 4\n",
    "\n",
    "# Implements a deep Graph Neural Network\n",
    "gnn_layer = GNN(params)\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "\n",
    "\n",
    "# Computes the mean along segments of a tensor\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "avg = segment_mean(\n",
    "    data = gnn_out,\n",
    "    segment_ids = node2graph\n",
    ")\n",
    "\n",
    "# Define the out put layer of the model\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "\n",
    "\n",
    "# Creating the model\n",
    "modelV4 = Model(\n",
    "    inputs = {\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs = pred\n",
    ")\n",
    "modelV4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T06:14:27.568889Z",
     "iopub.status.busy": "2023-04-28T06:14:27.568525Z",
     "iopub.status.idle": "2023-04-28T06:14:27.583384Z",
     "shell.execute_reply": "2023-04-28T06:14:27.582093Z",
     "shell.execute_reply.started": "2023-04-28T06:14:27.568856Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "modelV4.compile(\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T06:45:49.695061Z",
     "iopub.status.busy": "2023-04-28T06:45:49.694532Z",
     "iopub.status.idle": "2023-04-28T07:08:57.247352Z",
     "shell.execute_reply": "2023-04-28T07:08:57.245741Z",
     "shell.execute_reply.started": "2023-04-28T06:45:49.695015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.6175 - auc: 0.7150 - val_loss: 0.6076 - val_auc: 0.7443\n",
      "Epoch 2/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.5843 - auc: 0.7591 - val_loss: 0.5754 - val_auc: 0.7752\n",
      "Epoch 3/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.5575 - auc: 0.7888 - val_loss: 0.5552 - val_auc: 0.7978\n",
      "Epoch 4/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.5412 - auc: 0.8036 - val_loss: 0.5330 - val_auc: 0.8109\n",
      "Epoch 5/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.5259 - auc: 0.8169 - val_loss: 0.5433 - val_auc: 0.8130\n",
      "Epoch 6/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.5119 - auc: 0.8279 - val_loss: 0.4991 - val_auc: 0.8393\n",
      "Epoch 7/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.4960 - auc: 0.8401 - val_loss: 0.4929 - val_auc: 0.8450\n",
      "Epoch 8/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.4862 - auc: 0.8478 - val_loss: 0.4831 - val_auc: 0.8539\n",
      "Epoch 9/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.4752 - auc: 0.8559 - val_loss: 0.4675 - val_auc: 0.8630\n",
      "Epoch 10/25\n",
      "2530/2530 [==============================] - 57s 23ms/step - loss: 0.4655 - auc: 0.8625 - val_loss: 0.4469 - val_auc: 0.8750\n",
      "Epoch 11/25\n",
      "2530/2530 [==============================] - 57s 22ms/step - loss: 0.4564 - auc: 0.8686 - val_loss: 0.4350 - val_auc: 0.8818\n",
      "Epoch 12/25\n",
      "2530/2530 [==============================] - 59s 23ms/step - loss: 0.4520 - auc: 0.8716 - val_loss: 0.4435 - val_auc: 0.8766\n",
      "Epoch 13/25\n",
      "2530/2530 [==============================] - 53s 21ms/step - loss: 0.4438 - auc: 0.8767 - val_loss: 0.4202 - val_auc: 0.8897\n",
      "Epoch 14/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.4370 - auc: 0.8808 - val_loss: 0.4178 - val_auc: 0.8915\n",
      "Epoch 15/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.4276 - auc: 0.8862 - val_loss: 0.4214 - val_auc: 0.8896\n",
      "Epoch 16/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.4237 - auc: 0.8881 - val_loss: 0.3973 - val_auc: 0.9013\n",
      "Epoch 17/25\n",
      "2530/2530 [==============================] - 53s 21ms/step - loss: 0.4207 - auc: 0.8902 - val_loss: 0.4226 - val_auc: 0.8906\n",
      "Epoch 18/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.4155 - auc: 0.8934 - val_loss: 0.3936 - val_auc: 0.9033\n",
      "Epoch 19/25\n",
      "2530/2530 [==============================] - 53s 21ms/step - loss: 0.4076 - auc: 0.8972 - val_loss: 0.4066 - val_auc: 0.8980\n",
      "Epoch 20/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.4048 - auc: 0.8991 - val_loss: 0.4001 - val_auc: 0.9047\n",
      "Epoch 21/25\n",
      "2530/2530 [==============================] - 57s 22ms/step - loss: 0.3980 - auc: 0.9024 - val_loss: 0.3746 - val_auc: 0.9136\n",
      "Epoch 22/25\n",
      "2530/2530 [==============================] - 57s 23ms/step - loss: 0.3956 - auc: 0.9046 - val_loss: 0.3850 - val_auc: 0.9087\n",
      "Epoch 23/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.3990 - auc: 0.9028 - val_loss: 0.3834 - val_auc: 0.9142\n",
      "Epoch 24/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.3879 - auc: 0.9081 - val_loss: 0.3755 - val_auc: 0.9144\n",
      "Epoch 25/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.3848 - auc: 0.9094 - val_loss: 0.3681 - val_auc: 0.9194\n",
      "771/771 [==============================] - 7s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV4, training_set, validation_set, batch_size=16, num_epochs=25)\n",
    "y_pred = get_predictions(modelV4, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Fourth_Trial.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 90.94 %</br>\n",
    "**validatation accuracy (auc)**: 91.94 %</br>\n",
    "**Testing Accuracy (auc)**: 84.614 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "Here, we used RGAT (Relational Graph Attention Networks) as message passing method and it improved the performance.</br></br>\n",
    "The reason why RGATs may improve the accuracy more than RGCNs in certain cases is that attention mechanisms can help the model focus on the most relevant nodes and edges in the graph, and capture more complex relationships between them. By assigning different weights to different nodes and edges based on their importance, RGATs can improve the accuracy of the model and capture more fine-grained information about the graph.</br>\n",
    "\n",
    "In contrast, RGCNs use weight-sharing to ensure that the same parameters are used for each edge type. While this can be effective in some cases, it may not be sufficient to capture the full complexity of the graph, especially if there are significant differences between the different types of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Trile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :**\n",
    "\n",
    "The model uses a single GNN layer with hyperparameters configured to use a **relational graph attention network** (RGAT) message passing method. The output of the GNN layer is passed through an **attention mechanism**, which applies **a dense layer with a hyperbolic tangent** activation function, followed by a **softmax** activation function, to compute attention weights. These weights are then used to compute a **weighted average** of the node embeddings, which is intended to highlight the most important nodes for the prediction task.\n",
    "\n",
    "The output of the attention mechanism is passed through a dense layer with a **sigmoid** activation function to produce the final predictions. The model is compiled using the Adam optimizer and binary cross-entropy loss function, and the accuracy metric is used to evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:44:57.821333Z",
     "iopub.status.busy": "2023-04-28T14:44:57.820547Z",
     "iopub.status.idle": "2023-04-28T14:45:00.990277Z",
     "shell.execute_reply": "2023-04-28T14:45:00.989073Z",
     "shell.execute_reply.started": "2023-04-28T14:44:57.821277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " gnn (GNN)                      (None, 32)           22720       ['embedding[0][0]',              \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            33          ['gnn[0][0]']                    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1)            0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1)            0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           64          ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 32)           0           ['gnn[0][0]',                    \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['multiply[0][0]',               \n",
      " da)                                                              'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,850\n",
      "Trainable params: 32,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params['hidden_dim'] = 32\n",
    "params['num_heads'] = 4\n",
    "params['dropout_rate'] = 0.2\n",
    "params['message_calculation_class'] = 'RGAT'\n",
    "gnn_layer1 = GNN(params)(gnn_input)\n",
    "\n",
    "attn = layers.Dense(1, activation=\"tanh\")(gnn_layer1)\n",
    "attn = layers.Flatten()(attn)\n",
    "attn = layers.Activation(\"softmax\")(attn)\n",
    "attn = layers.Dense(32)(attn)\n",
    "# attn = layers.Reshape((32))(attn)  # Add a Reshape layer to convert attn to (None, 1, 20)\n",
    "# attn = layers.Permute([2, 1])(attn)\n",
    "attn_out = layers.Multiply()([gnn_layer1, attn])\n",
    "attn_out = segment_mean(data =attn_out, segment_ids = node2graph) \n",
    "\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(attn_out)\n",
    "labels = keras.Input(batch_shape=(None,))\n",
    "labels = layers.Reshape((1,))(labels)  # Reshape labels to have shape (None, 1)\n",
    "\n",
    "\n",
    "modelV5 = Model(inputs = {\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    }, outputs=output)\n",
    "modelV5.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "modelV5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T14:45:00.992104Z",
     "iopub.status.busy": "2023-04-28T14:45:00.991758Z",
     "iopub.status.idle": "2023-04-28T15:08:00.527235Z",
     "shell.execute_reply": "2023-04-28T15:08:00.526012Z",
     "shell.execute_reply.started": "2023-04-28T14:45:00.992072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2530/2530 [==============================] - 63s 22ms/step - loss: 0.6230 - accuracy: 0.6556 - val_loss: 0.5911 - val_accuracy: 0.7067\n",
      "Epoch 2/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.5814 - accuracy: 0.7066 - val_loss: 0.5739 - val_accuracy: 0.7153\n",
      "Epoch 3/25\n",
      "2530/2530 [==============================] - 57s 22ms/step - loss: 0.5547 - accuracy: 0.7273 - val_loss: 0.5356 - val_accuracy: 0.7425\n",
      "Epoch 4/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.5329 - accuracy: 0.7405 - val_loss: 0.5165 - val_accuracy: 0.7546\n",
      "Epoch 5/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.5200 - accuracy: 0.7487 - val_loss: 0.5032 - val_accuracy: 0.7572\n",
      "Epoch 6/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.5055 - accuracy: 0.7586 - val_loss: 0.4857 - val_accuracy: 0.7740\n",
      "Epoch 7/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.4922 - accuracy: 0.7657 - val_loss: 0.4762 - val_accuracy: 0.7779\n",
      "Epoch 8/25\n",
      "2530/2530 [==============================] - 54s 22ms/step - loss: 0.4773 - accuracy: 0.7736 - val_loss: 0.4509 - val_accuracy: 0.7910\n",
      "Epoch 9/25\n",
      "2530/2530 [==============================] - 57s 23ms/step - loss: 0.4637 - accuracy: 0.7806 - val_loss: 0.4462 - val_accuracy: 0.7935\n",
      "Epoch 10/25\n",
      "2530/2530 [==============================] - 57s 22ms/step - loss: 0.4540 - accuracy: 0.7870 - val_loss: 0.4363 - val_accuracy: 0.7975\n",
      "Epoch 11/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.4466 - accuracy: 0.7914 - val_loss: 0.4267 - val_accuracy: 0.8008\n",
      "Epoch 12/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.4382 - accuracy: 0.7953 - val_loss: 0.4317 - val_accuracy: 0.8048\n",
      "Epoch 13/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.4251 - accuracy: 0.8037 - val_loss: 0.4119 - val_accuracy: 0.8073\n",
      "Epoch 14/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.4201 - accuracy: 0.8073 - val_loss: 0.4034 - val_accuracy: 0.8209\n",
      "Epoch 15/25\n",
      "2530/2530 [==============================] - 53s 21ms/step - loss: 0.4119 - accuracy: 0.8118 - val_loss: 0.3840 - val_accuracy: 0.8269\n",
      "Epoch 16/25\n",
      "2530/2530 [==============================] - 53s 21ms/step - loss: 0.4047 - accuracy: 0.8139 - val_loss: 0.3825 - val_accuracy: 0.8240\n",
      "Epoch 17/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.3991 - accuracy: 0.8197 - val_loss: 0.4017 - val_accuracy: 0.8223\n",
      "Epoch 18/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.3898 - accuracy: 0.8228 - val_loss: 0.3788 - val_accuracy: 0.8241\n",
      "Epoch 19/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.3826 - accuracy: 0.8278 - val_loss: 0.3684 - val_accuracy: 0.8367\n",
      "Epoch 20/25\n",
      "2530/2530 [==============================] - 56s 22ms/step - loss: 0.3799 - accuracy: 0.8297 - val_loss: 0.3573 - val_accuracy: 0.8355\n",
      "Epoch 21/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.3729 - accuracy: 0.8338 - val_loss: 0.3543 - val_accuracy: 0.8401\n",
      "Epoch 22/25\n",
      "2530/2530 [==============================] - 53s 21ms/step - loss: 0.3683 - accuracy: 0.8362 - val_loss: 0.3481 - val_accuracy: 0.8506\n",
      "Epoch 23/25\n",
      "2530/2530 [==============================] - 53s 21ms/step - loss: 0.3621 - accuracy: 0.8391 - val_loss: 0.3446 - val_accuracy: 0.8516\n",
      "Epoch 24/25\n",
      "2530/2530 [==============================] - 54s 21ms/step - loss: 0.3653 - accuracy: 0.8382 - val_loss: 0.3377 - val_accuracy: 0.8570\n",
      "Epoch 25/25\n",
      "2530/2530 [==============================] - 55s 22ms/step - loss: 0.3583 - accuracy: 0.8425 - val_loss: 0.3359 - val_accuracy: 0.8544\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV5, training_set, validation_set, batch_size=16, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:08:00.534431Z",
     "iopub.status.busy": "2023-04-28T15:08:00.533817Z",
     "iopub.status.idle": "2023-04-28T15:08:07.219503Z",
     "shell.execute_reply": "2023-04-28T15:08:07.218462Z",
     "shell.execute_reply.started": "2023-04-28T15:08:00.534367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 6s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV5, testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:08:07.221333Z",
     "iopub.status.busy": "2023-04-28T15:08:07.221016Z",
     "iopub.status.idle": "2023-04-28T15:08:07.259076Z",
     "shell.execute_reply": "2023-04-28T15:08:07.257953Z",
     "shell.execute_reply.started": "2023-04-28T15:08:07.221304Z"
    }
   },
   "outputs": [],
   "source": [
    "save_predictions_to_csv(y_pred, 'Fifth_Trial.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 84.25 %</br>\n",
    "**validatation accuracy (auc)**: 85.44 %</br>\n",
    "**Testing Accuracy (auc)**: 84.617 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "When we used more complex model the performance didn't improve that maybe our data is small so more complex model will not add more benfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sixth Trile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :**\n",
    "\n",
    "**The model uses two GNN layers**, each with a different set of hyperparameters, to learn representations of the molecular graphs. The outputs of the GNN layers are then pooled **using mean pooling**, and **concatenated together**. The resulting pooled outputs are then passed through a **dropout layer** for regularization, and finally through **a dense layer** with a sigmoid activation function to produce the final predictions.\n",
    "\n",
    "**The model is compiled** using the AdamW optimizer and binary cross-entropy loss function, and the accuracy metric is used to evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T12:51:15.363462Z",
     "iopub.status.busy": "2023-04-25T12:51:15.362277Z",
     "iopub.status.idle": "2023-04-25T12:51:17.955219Z",
     "shell.execute_reply": "2023-04-25T12:51:17.953744Z",
     "shell.execute_reply.started": "2023-04-25T12:51:15.363420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_4 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 20)           10000       ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  ()                  0           ['tf.math.reduce_max_4[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_3 (GNN)                    (None, 64)           71552       ['embedding_3[0][0]',            \n",
      "                                                                  'input_14[0][0]',               \n",
      "                                                                  'input_15[0][0]',               \n",
      "                                                                  'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " gnn_5 (GNN)                    (None, 32)           22720       ['embedding_3[0][0]',            \n",
      "                                                                  'input_14[0][0]',               \n",
      "                                                                  'input_15[0][0]',               \n",
      "                                                                  'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_mean   (None, 64)          0           ['gnn_3[0][0]',                  \n",
      " (TFOpLambda)                                                     'input_15[0][0]',               \n",
      "                                                                  'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_mean_  (None, 32)          0           ['gnn_5[0][0]',                  \n",
      " 1 (TFOpLambda)                                                   'input_15[0][0]',               \n",
      "                                                                  'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 96)           0           ['tf.math.unsorted_segment_mean[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'tf.math.unsorted_segment_mean_1\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 96)           0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            97          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 104,369\n",
      "Trainable params: 104,369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from tf2_gnn.utils.general import get_aggregate_method_from_str\n",
    "\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the GNN layers\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_heads\"] = 8\n",
    "params[\"dropout_rate\"] = 0.2\n",
    "params[\"message_calculation_class\"] = \"RGCN\"\n",
    "gnn_layer1 = GNN(params)\n",
    "gnn_out1 = gnn_layer1(gnn_input)\n",
    "\n",
    "params[\"hidden_dim\"] = 32\n",
    "params[\"num_heads\"] = 4\n",
    "params[\"dropout_rate\"] = 0.1\n",
    "params[\"message_calculation_class\"] = \"RGAT\"\n",
    "gnn_layer2 = GNN(params)\n",
    "gnn_out2 = gnn_layer2(gnn_input)\n",
    "\n",
    "gnn_layer2 = GNN(params)\n",
    "gnn_out2 = gnn_layer2(gnn_input)\n",
    "\n",
    "# Apply mean pooling to the outputs of the GNN layers\n",
    "pool_out1 = tf.math.unsorted_segment_mean(gnn_out1, node2graph, num_graph)\n",
    "pool_out2 = tf.math.unsorted_segment_mean(gnn_out2, node2graph, num_graph)\n",
    "\n",
    "# Concatenate the pooled outputs\n",
    "pool_out = layers.concatenate([pool_out1, pool_out2])\n",
    "\n",
    "# Add dropout regularization\n",
    "dropout = layers.Dropout(0.3)(pool_out)\n",
    "\n",
    "# Define the output layer of the model\n",
    "pred = layers.Dense(1, activation=\"sigmoid\")(dropout)\n",
    "\n",
    "# Create the model\n",
    "modelV6 = Model(inputs={\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },  outputs=pred)\n",
    "\n",
    "# Use AdamW optimizer and binary cross-entropy loss\n",
    "opt = Adam(learning_rate=0.001)\n",
    "modelV6.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "modelV6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T12:51:17.957603Z",
     "iopub.status.busy": "2023-04-25T12:51:17.957234Z",
     "iopub.status.idle": "2023-04-25T13:27:50.202905Z",
     "shell.execute_reply": "2023-04-25T13:27:50.201492Z",
     "shell.execute_reply.started": "2023-04-25T12:51:17.957567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2530/2530 [==============================] - 97s 34ms/step - loss: 0.6077 - accuracy: 0.6742 - val_loss: 0.5663 - val_accuracy: 0.7099\n",
      "Epoch 2/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.5520 - accuracy: 0.7282 - val_loss: 0.5352 - val_accuracy: 0.7375\n",
      "Epoch 3/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.5338 - accuracy: 0.7363 - val_loss: 0.5204 - val_accuracy: 0.7405\n",
      "Epoch 4/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.5153 - accuracy: 0.7447 - val_loss: 0.5050 - val_accuracy: 0.7482\n",
      "Epoch 5/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.5013 - accuracy: 0.7569 - val_loss: 0.4925 - val_accuracy: 0.7676\n",
      "Epoch 6/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.4865 - accuracy: 0.7702 - val_loss: 0.4787 - val_accuracy: 0.7684\n",
      "Epoch 7/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.4783 - accuracy: 0.7744 - val_loss: 0.4806 - val_accuracy: 0.7674\n",
      "Epoch 8/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.4606 - accuracy: 0.7856 - val_loss: 0.4483 - val_accuracy: 0.7863\n",
      "Epoch 9/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.4442 - accuracy: 0.7938 - val_loss: 0.4357 - val_accuracy: 0.7991\n",
      "Epoch 10/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.4328 - accuracy: 0.8009 - val_loss: 0.4246 - val_accuracy: 0.7984\n",
      "Epoch 11/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.4244 - accuracy: 0.8061 - val_loss: 0.4052 - val_accuracy: 0.8125\n",
      "Epoch 12/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.4068 - accuracy: 0.8153 - val_loss: 0.3998 - val_accuracy: 0.8163\n",
      "Epoch 13/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3933 - accuracy: 0.8208 - val_loss: 0.3854 - val_accuracy: 0.8254\n",
      "Epoch 14/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3831 - accuracy: 0.8257 - val_loss: 0.3696 - val_accuracy: 0.8367\n",
      "Epoch 15/25\n",
      "2530/2530 [==============================] - 87s 34ms/step - loss: 0.3706 - accuracy: 0.8336 - val_loss: 0.3922 - val_accuracy: 0.8212\n",
      "Epoch 16/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3573 - accuracy: 0.8389 - val_loss: 0.3421 - val_accuracy: 0.8496\n",
      "Epoch 17/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3524 - accuracy: 0.8438 - val_loss: 0.3439 - val_accuracy: 0.8478\n",
      "Epoch 18/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3570 - accuracy: 0.8413 - val_loss: 0.3328 - val_accuracy: 0.8565\n",
      "Epoch 19/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3482 - accuracy: 0.8445 - val_loss: 0.3341 - val_accuracy: 0.8554\n",
      "Epoch 20/25\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3374 - accuracy: 0.8541 - val_loss: 0.3138 - val_accuracy: 0.8661\n",
      "Epoch 21/25\n",
      "2530/2530 [==============================] - 87s 34ms/step - loss: 0.3238 - accuracy: 0.8575 - val_loss: 0.3051 - val_accuracy: 0.8752\n",
      "Epoch 22/25\n",
      "2530/2530 [==============================] - 87s 34ms/step - loss: 0.3089 - accuracy: 0.8672 - val_loss: 0.2982 - val_accuracy: 0.8757\n",
      "Epoch 23/25\n",
      "2530/2530 [==============================] - 87s 34ms/step - loss: 0.3049 - accuracy: 0.8696 - val_loss: 0.3016 - val_accuracy: 0.8709\n",
      "Epoch 24/25\n",
      "2530/2530 [==============================] - 87s 35ms/step - loss: 0.2964 - accuracy: 0.8723 - val_loss: 0.2652 - val_accuracy: 0.8898\n",
      "Epoch 25/25\n",
      "2530/2530 [==============================] - 87s 35ms/step - loss: 0.2879 - accuracy: 0.8785 - val_loss: 0.2818 - val_accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV6, training_set, validation_set, batch_size=16, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T13:27:50.206055Z",
     "iopub.status.busy": "2023-04-25T13:27:50.205550Z",
     "iopub.status.idle": "2023-04-25T13:27:59.332251Z",
     "shell.execute_reply": "2023-04-25T13:27:59.330970Z",
     "shell.execute_reply.started": "2023-04-25T13:27:50.206005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 9s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV6, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Sixth_Trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 87.85 %</br>\n",
    "**validatation accuracy (auc)**: 88.13 %</br>\n",
    "**Testing Accuracy (auc)**: 83.11 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "Here we tried to use more complex model as we used two layers with two different  message passing methods (RGAT,RGCN)But the accuracy decreased then trial number foure</br> \n",
    "The reasone for that may be because of: </br>Interference between message passing methods: If the RGAT and RGCN message passing methods are not complementary or compatible, they may interfere with each other and degrade the performance of the model. It's possible that the two-layer model did not effectively combine the information from the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seventh Trile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :**  Training data set without upsampling\n",
    "\n",
    "**The Model Used is :**\n",
    "The model uses a **single GNN layer** with hyperparameters configured to use a **Gated Graph Neural Networks** (GGNN) message passing method. The output of the GNN layer is passed through a function called **segment_mean**, which computes the mean of the node embeddings for each graph in the batch. This is intended to summarize the information from the nodes into a single vector per graph, which can be used for the prediction task.\n",
    "\n",
    "The output of the segment_mean function is passed through a **dense layer** with a **sigmoid** activation function to produce the final predictions. The model is compiled using the **binary cross-entropy loss** function and the **Adam optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T16:09:44.369448Z",
     "iopub.status.busy": "2023-04-25T16:09:44.369024Z",
     "iopub.status.idle": "2023-04-25T16:09:45.256352Z",
     "shell.execute_reply": "2023-04-25T16:09:45.254832Z",
     "shell.execute_reply.started": "2023-04-25T16:09:44.369413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_108 (InputLayer)         [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_106 (InputLayer)         [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_54 (TFOpLam  ()                  0           ['input_108[0][0]']              \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_34 (Embedding)       (None, 20)           10000       ['input_106[0][0]']              \n",
      "                                                                                                  \n",
      " input_107 (InputLayer)         [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  ()                  0           ['tf.math.reduce_max_54[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_52 (GNN)                   (None, 64)           171392      ['embedding_34[0][0]',           \n",
      "                                                                  'input_107[0][0]',              \n",
      "                                                                  'input_108[0][0]',              \n",
      "                                                                  'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.segment_mean_18 (TFOpL  (None, 64)          0           ['gnn_52[0][0]',                 \n",
      " ambda)                                                           'input_108[0][0]']              \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 1)            65          ['tf.math.segment_mean_18[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 181,457\n",
      "Trainable params: 181,457\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "# configure the hyperparameters of GNN layers\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "# \n",
    "# frist load the defualt hyperparameters\n",
    "params = GNN.get_default_hyperparameters()\n",
    "# sets the size of the output of all message passing layers\n",
    "params[\"hidden_dim\"] = 64\n",
    "# configures the message passing style to be GGNN (Gated Graph Neural Networks)\n",
    "params['message_calculation_class'] = 'GGNN'\n",
    "\n",
    "# Implements a deep Graph Neural Network\n",
    "gnn_layer = GNN(params)\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "\n",
    "\n",
    "# Computes the mean along segments of a tensor\n",
    "avg = segment_mean(\n",
    "    data = gnn_out,\n",
    "    segment_ids = node2graph\n",
    ")\n",
    "\n",
    "# Define the out put layer of the model\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "\n",
    "\n",
    "# Creating the model\n",
    "modelV7 = Model(\n",
    "    inputs={\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs = pred\n",
    ")\n",
    "modelV7.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "modelV7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T16:09:45.258699Z",
     "iopub.status.busy": "2023-04-25T16:09:45.258343Z",
     "iopub.status.idle": "2023-04-25T16:53:09.567871Z",
     "shell.execute_reply": "2023-04-25T16:53:09.566324Z",
     "shell.execute_reply.started": "2023-04-25T16:09:45.258664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2530/2530 [==============================] - 109s 41ms/step - loss: 0.5944 - accuracy: 0.6824 - val_loss: 0.5528 - val_accuracy: 0.7267\n",
      "Epoch 2/25\n",
      "2530/2530 [==============================] - 104s 41ms/step - loss: 0.5327 - accuracy: 0.7410 - val_loss: 0.5065 - val_accuracy: 0.7607\n",
      "Epoch 3/25\n",
      "1449/2530 [================>.............] - ETA: 41s - loss: 0.4857 - accuracy: 0.7738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2530/2530 [==============================] - 105s 41ms/step - loss: 0.4296 - accuracy: 0.8062 - val_loss: 0.4117 - val_accuracy: 0.8247\n",
      "Epoch 5/25\n",
      "2530/2530 [==============================] - 104s 41ms/step - loss: 0.3900 - accuracy: 0.8280 - val_loss: 0.3898 - val_accuracy: 0.8306\n",
      "Epoch 6/25\n",
      "1773/2530 [====================>.........] - ETA: 29s - loss: 0.3642 - accuracy: 0.8409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2530/2530 [==============================] - 102s 40ms/step - loss: 0.3320 - accuracy: 0.8595 - val_loss: 0.3226 - val_accuracy: 0.8596\n",
      "Epoch 8/25\n",
      "2530/2530 [==============================] - 103s 41ms/step - loss: 0.3037 - accuracy: 0.8722 - val_loss: 0.3130 - val_accuracy: 0.8726\n",
      "Epoch 9/25\n",
      "2471/2530 [============================>.] - ETA: 2s - loss: 0.2778 - accuracy: 0.8865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2530/2530 [==============================] - 102s 40ms/step - loss: 0.3008 - accuracy: 0.8744 - val_loss: 0.2470 - val_accuracy: 0.9053\n",
      "Epoch 11/25\n",
      "2530/2530 [==============================] - 102s 41ms/step - loss: 0.2435 - accuracy: 0.9035 - val_loss: 0.2430 - val_accuracy: 0.9034\n",
      "Epoch 12/25\n",
      "2530/2530 [==============================] - 107s 42ms/step - loss: 0.3644 - accuracy: 0.8376 - val_loss: 0.3504 - val_accuracy: 0.8437\n",
      "Epoch 17/25\n",
      "2530/2530 [==============================] - 102s 40ms/step - loss: 0.3136 - accuracy: 0.8679 - val_loss: 0.2847 - val_accuracy: 0.8906\n",
      "Epoch 18/25\n",
      "2530/2530 [==============================] - 104s 41ms/step - loss: 0.2611 - accuracy: 0.8931 - val_loss: 0.2781 - val_accuracy: 0.8944\n",
      "Epoch 19/25\n",
      "2530/2530 [==============================] - 104s 41ms/step - loss: 0.2426 - accuracy: 0.9029 - val_loss: 0.2537 - val_accuracy: 0.9048\n",
      "Epoch 20/25\n",
      "2530/2530 [==============================] - 107s 42ms/step - loss: 0.2187 - accuracy: 0.9152 - val_loss: 0.2203 - val_accuracy: 0.9201\n",
      "Epoch 21/25\n",
      "2530/2530 [==============================] - 104s 41ms/step - loss: 0.2024 - accuracy: 0.9222 - val_loss: 0.2167 - val_accuracy: 0.9219\n",
      "Epoch 22/25\n",
      "2530/2530 [==============================] - 105s 41ms/step - loss: 0.1829 - accuracy: 0.9320 - val_loss: 0.2129 - val_accuracy: 0.9254\n",
      "Epoch 23/25\n",
      "2530/2530 [==============================] - 109s 43ms/step - loss: 0.1777 - accuracy: 0.9338 - val_loss: 0.1987 - val_accuracy: 0.9304\n",
      "Epoch 24/25\n",
      "2530/2530 [==============================] - 103s 41ms/step - loss: 0.1695 - accuracy: 0.9377 - val_loss: 0.1882 - val_accuracy: 0.9350\n",
      "Epoch 25/25\n",
      "2530/2530 [==============================] - 103s 41ms/step - loss: 0.1613 - accuracy: 0.9412 - val_loss: 0.1633 - val_accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV7, training_set, validation_set, batch_size=16, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T16:53:09.573258Z",
     "iopub.status.busy": "2023-04-25T16:53:09.571434Z",
     "iopub.status.idle": "2023-04-25T16:53:20.531095Z",
     "shell.execute_reply": "2023-04-25T16:53:20.529817Z",
     "shell.execute_reply.started": "2023-04-25T16:53:09.573193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 11s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV7, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Seventh_Trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 94.12 %</br>\n",
    "**validatation accuracy (auc)**: 94.55 %</br>\n",
    "**Testing Accuracy (auc)**: 85.64 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "When we tried to use Gated Graph Neural Networks (GGNN) message passing method it improve test accuracy more than RGCN,RGAT methods.</br>\n",
    "\n",
    "The reason why GGNNs may improve the accuracy more than RGCNs or RGATs in certain cases is that they can capture more complex temporal dependencies between the nodes in the graph. Unlike RGCNs and RGATs, which perform message passing in a fixed order and do not consider the temporal order of the nodes, GGNNs use recurrent units to update the node representations in a way that depends on the previous states of the nodes. This allows GGNNs to capture more fine-grained information about the graph and improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eighth trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :**\n",
    "\n",
    "**The model uses two GNN layers**, with same set of hyperparameters configured to use (**GGNN**) message passing method, to learn representations of the molecular graphs. The outputs of the GNN layers are then pooled **using mean pooling**, and **concatenated together**. The resulting pooled outputs are then passed through a **dropout layer** for regularization, and finally through **a dense layer** with a sigmoid activation function to produce the final predictions.\n",
    "\n",
    "**The model is compiled** using the AdamW optimizer and binary cross-entropy loss function, and the accuracy metric is used to evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:01:54.808149Z",
     "iopub.status.busy": "2023-04-25T17:01:54.806829Z",
     "iopub.status.idle": "2023-04-25T17:01:57.181787Z",
     "shell.execute_reply": "2023-04-25T17:01:57.180584Z",
     "shell.execute_reply.started": "2023-04-25T17:01:54.808095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_111 (InputLayer)         [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_109 (InputLayer)         [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_55 (TFOpLam  ()                  0           ['input_111[0][0]']              \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_35 (Embedding)       (None, 20)           10000       ['input_109[0][0]']              \n",
      "                                                                                                  \n",
      " input_110 (InputLayer)         [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  ()                  0           ['tf.math.reduce_max_55[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_53 (GNN)                   (None, 64)           171392      ['embedding_35[0][0]',           \n",
      "                                                                  'input_110[0][0]',              \n",
      "                                                                  'input_111[0][0]',              \n",
      "                                                                  'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " gnn_55 (GNN)                   (None, 32)           47808       ['embedding_35[0][0]',           \n",
      "                                                                  'input_110[0][0]',              \n",
      "                                                                  'input_111[0][0]',              \n",
      "                                                                  'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_mean_  (None, 64)          0           ['gnn_53[0][0]',                 \n",
      " 2 (TFOpLambda)                                                   'input_111[0][0]',              \n",
      "                                                                  'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_mean_  (None, 32)          0           ['gnn_55[0][0]',                 \n",
      " 3 (TFOpLambda)                                                   'input_111[0][0]',              \n",
      "                                                                  'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 96)           0           ['tf.math.unsorted_segment_mean_2\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'tf.math.unsorted_segment_mean_3\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 96)           0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 1)            97          ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 229,297\n",
      "Trainable params: 229,297\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from tf2_gnn.utils.general import get_aggregate_method_from_str\n",
    "\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the GNN layers\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_heads\"] = 8\n",
    "params[\"dropout_rate\"] = 0.2\n",
    "params[\"message_calculation_class\"] = \"GGNN\"\n",
    "gnn_layer1 = GNN(params)\n",
    "gnn_out1 = gnn_layer1(gnn_input)\n",
    "\n",
    "params[\"hidden_dim\"] = 32\n",
    "params[\"num_heads\"] = 4\n",
    "params[\"dropout_rate\"] = 0.1\n",
    "params[\"message_calculation_class\"] = \"GGNN\"\n",
    "gnn_layer2 = GNN(params)\n",
    "gnn_out2 = gnn_layer2(gnn_input)\n",
    "\n",
    "gnn_layer2 = GNN(params)\n",
    "gnn_out2 = gnn_layer2(gnn_input)\n",
    "\n",
    "# Apply mean pooling to the outputs of the GNN layers\n",
    "pool_out1 = tf.math.unsorted_segment_mean(gnn_out1, node2graph, num_graph)\n",
    "pool_out2 = tf.math.unsorted_segment_mean(gnn_out2, node2graph, num_graph)\n",
    "\n",
    "# Concatenate the pooled outputs\n",
    "pool_out = layers.concatenate([pool_out1, pool_out2])\n",
    "\n",
    "# Add dropout regularization\n",
    "dropout = layers.Dropout(0.3)(pool_out)\n",
    "\n",
    "# Define the output layer of the model\n",
    "pred = layers.Dense(1, activation=\"sigmoid\")(dropout)\n",
    "\n",
    "# Create the model\n",
    "modelV8 = Model(inputs={\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },  outputs=pred)\n",
    "\n",
    "# Use AdamW optimizer and binary cross-entropy loss\n",
    "opt = Adam(learning_rate=0.001)\n",
    "modelV8.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "modelV8.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:39:56.308878Z",
     "iopub.status.busy": "2023-04-25T17:39:56.308447Z",
     "iopub.status.idle": "2023-04-25T17:51:18.350225Z",
     "shell.execute_reply": "2023-04-25T17:51:18.348822Z",
     "shell.execute_reply.started": "2023-04-25T17:39:56.308844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2530/2530 [==============================] - 127s 50ms/step - loss: 0.2444 - accuracy: 0.9016 - val_loss: 0.2670 - val_accuracy: 0.9010\n",
      "Epoch 2/5\n",
      "2530/2530 [==============================] - 127s 50ms/step - loss: 0.2644 - accuracy: 0.8937 - val_loss: 0.2429 - val_accuracy: 0.9097\n",
      "Epoch 3/5\n",
      "2530/2530 [==============================] - 125s 50ms/step - loss: 0.2462 - accuracy: 0.9011 - val_loss: 0.2408 - val_accuracy: 0.9115\n",
      "Epoch 4/5\n",
      "2530/2530 [==============================] - 124s 49ms/step - loss: 0.2292 - accuracy: 0.9111 - val_loss: 0.2524 - val_accuracy: 0.9147\n",
      "Epoch 5/5\n",
      "2530/2530 [==============================] - 126s 50ms/step - loss: 0.2258 - accuracy: 0.9126 - val_loss: 0.2532 - val_accuracy: 0.9142\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV8, training_set, validation_set, batch_size=16, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:55:07.523788Z",
     "iopub.status.busy": "2023-04-25T17:55:07.523318Z",
     "iopub.status.idle": "2023-04-25T17:55:28.739192Z",
     "shell.execute_reply": "2023-04-25T17:55:28.737505Z",
     "shell.execute_reply.started": "2023-04-25T17:55:07.523749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 13s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV8, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Eighth_Trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 91.26 %</br>\n",
    "**validatation accuracy (auc)**: 91.42 %</br>\n",
    "**Testing Accuracy (auc)**: 85.67 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "Here we tried to use more complex model as we used two layers with same  message passing methods (GGNN) But the accuracy didn't improve then the the simple model</br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ninth Trial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :**\n",
    "\n",
    "**The model uses three GNN layers**, with same set of hyperparameters configured to use (**RGAT**) message passing method, to learn representations of the molecular graphs. There are **dropout layer**  detween each layer for regularization. The output of the GNN layers is passed through a function called **segment_mean**, which computes the mean of the node embeddings for each graph in the batch. This is intended to summarize the information from the nodes into a single vector per graph, which can be used for the prediction task.\n",
    "**The model is compiled** using the AdamW optimizer and binary cross-entropy loss function, and the accuracy metric is used to evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:14:14.589312Z",
     "iopub.status.busy": "2023-04-28T15:14:14.588159Z",
     "iopub.status.idle": "2023-04-28T15:14:17.022311Z",
     "shell.execute_reply": "2023-04-28T15:14:17.021373Z",
     "shell.execute_reply.started": "2023-04-28T15:14:14.589264Z"
    }
   },
   "outputs": [],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_heads\"] = 4\n",
    "params[\"dropout_rate\"] = 0.2\n",
    "params[\"message_calculation_class\"] = \"GGNN\"\n",
    "\n",
    "gnn_layer1 = GNN(params)\n",
    "gnn_out1 = Dropout(0.2)(gnn_layer1(gnn_input))\n",
    "\n",
    "gnn_layer2 = GNN(params)\n",
    "gnn_out2 = Dropout(0.2)(gnn_layer2(GNNInput(\n",
    "    node_features=gnn_out1,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph,\n",
    "    num_graphs=tf.reduce_max(node2graph) + 1,\n",
    ")))\n",
    "\n",
    "gnn_layer3 = GNN(params)\n",
    "gnn_out3 = Dropout(0.2)(gnn_layer3(GNNInput(\n",
    "    node_features=gnn_out2,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph,\n",
    "    num_graphs=tf.reduce_max(node2graph) + 1,\n",
    ")))\n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out3,\n",
    "    segment_ids=node2graph\n",
    ")\n",
    "\n",
    "pred = Dense(1, activation=\"sigmoid\")(avg)\n",
    "\n",
    "modelV9 = Model(inputs={\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    }, outputs=pred)\n",
    "modelV9.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:14:17.024487Z",
     "iopub.status.busy": "2023-04-28T15:14:17.023969Z",
     "iopub.status.idle": "2023-04-28T17:07:51.768076Z",
     "shell.execute_reply": "2023-04-28T17:07:51.766896Z",
     "shell.execute_reply.started": "2023-04-28T15:14:17.024455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2530/2530 [==============================] - 289s 109ms/step - loss: 0.6314 - accuracy: 0.6453 - val_loss: 0.6328 - val_accuracy: 0.6409\n",
      "Epoch 2/25\n",
      "2530/2530 [==============================] - 275s 109ms/step - loss: 0.6205 - accuracy: 0.6576 - val_loss: 0.6214 - val_accuracy: 0.6568\n",
      "Epoch 3/25\n",
      "2530/2530 [==============================] - 275s 109ms/step - loss: 0.6016 - accuracy: 0.6768 - val_loss: 0.5993 - val_accuracy: 0.6838\n",
      "Epoch 4/25\n",
      "2530/2530 [==============================] - 273s 108ms/step - loss: 0.5840 - accuracy: 0.6933 - val_loss: 0.5819 - val_accuracy: 0.6932\n",
      "Epoch 5/25\n",
      "2530/2530 [==============================] - 278s 110ms/step - loss: 0.5772 - accuracy: 0.6978 - val_loss: 0.6033 - val_accuracy: 0.6823\n",
      "Epoch 6/25\n",
      "2530/2530 [==============================] - 271s 107ms/step - loss: 0.5785 - accuracy: 0.6988 - val_loss: 0.5579 - val_accuracy: 0.7173\n",
      "Epoch 7/25\n",
      "2530/2530 [==============================] - 272s 108ms/step - loss: 0.5570 - accuracy: 0.7187 - val_loss: 0.5499 - val_accuracy: 0.7288\n",
      "Epoch 8/25\n",
      "2530/2530 [==============================] - 272s 108ms/step - loss: 0.5423 - accuracy: 0.7280 - val_loss: 0.5355 - val_accuracy: 0.7335\n",
      "Epoch 9/25\n",
      "2530/2530 [==============================] - 271s 107ms/step - loss: 0.5337 - accuracy: 0.7337 - val_loss: 0.5116 - val_accuracy: 0.7551\n",
      "Epoch 10/25\n",
      "2530/2530 [==============================] - 273s 108ms/step - loss: 0.5185 - accuracy: 0.7439 - val_loss: 0.4944 - val_accuracy: 0.7627\n",
      "Epoch 11/25\n",
      "2530/2530 [==============================] - 272s 108ms/step - loss: 0.5023 - accuracy: 0.7577 - val_loss: 0.4731 - val_accuracy: 0.7704\n",
      "Epoch 12/25\n",
      "2530/2530 [==============================] - 270s 107ms/step - loss: 0.4850 - accuracy: 0.7647 - val_loss: 0.4684 - val_accuracy: 0.7709\n",
      "Epoch 13/25\n",
      "2530/2530 [==============================] - 270s 107ms/step - loss: 0.4864 - accuracy: 0.7650 - val_loss: 0.4815 - val_accuracy: 0.7736\n",
      "Epoch 14/25\n",
      "2530/2530 [==============================] - 270s 107ms/step - loss: 0.4766 - accuracy: 0.7673 - val_loss: 0.4562 - val_accuracy: 0.7884\n",
      "Epoch 15/25\n",
      "2530/2530 [==============================] - 269s 106ms/step - loss: 0.4541 - accuracy: 0.7842 - val_loss: 0.4207 - val_accuracy: 0.8054\n",
      "Epoch 16/25\n",
      "2530/2530 [==============================] - 273s 108ms/step - loss: 0.4375 - accuracy: 0.7942 - val_loss: 0.4200 - val_accuracy: 0.8085\n",
      "Epoch 17/25\n",
      "2530/2530 [==============================] - 271s 107ms/step - loss: 0.4304 - accuracy: 0.7970 - val_loss: 0.4087 - val_accuracy: 0.8110\n",
      "Epoch 18/25\n",
      "2530/2530 [==============================] - 271s 107ms/step - loss: 0.4104 - accuracy: 0.8087 - val_loss: 0.4115 - val_accuracy: 0.8121\n",
      "Epoch 19/25\n",
      "2530/2530 [==============================] - 275s 109ms/step - loss: 0.4000 - accuracy: 0.8143 - val_loss: 0.4082 - val_accuracy: 0.8164\n",
      "Epoch 20/25\n",
      "2530/2530 [==============================] - 272s 108ms/step - loss: 0.3893 - accuracy: 0.8209 - val_loss: 0.3866 - val_accuracy: 0.8237\n",
      "Epoch 21/25\n",
      "2530/2530 [==============================] - 272s 108ms/step - loss: 0.3934 - accuracy: 0.8191 - val_loss: 0.4501 - val_accuracy: 0.7940\n",
      "Epoch 22/25\n",
      "2530/2530 [==============================] - 270s 107ms/step - loss: 0.3942 - accuracy: 0.8154 - val_loss: 0.4117 - val_accuracy: 0.8065\n",
      "Epoch 23/25\n",
      "2530/2530 [==============================] - 270s 107ms/step - loss: 0.3814 - accuracy: 0.8255 - val_loss: 0.3835 - val_accuracy: 0.8269\n",
      "Epoch 24/25\n",
      "2530/2530 [==============================] - 271s 107ms/step - loss: 0.3690 - accuracy: 0.8299 - val_loss: 0.3690 - val_accuracy: 0.8414\n",
      "Epoch 25/25\n",
      "2530/2530 [==============================] - 270s 107ms/step - loss: 0.3502 - accuracy: 0.8427 - val_loss: 0.3665 - val_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV9, training_set, validation_set, batch_size=16, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:07:51.770681Z",
     "iopub.status.busy": "2023-04-28T17:07:51.770153Z",
     "iopub.status.idle": "2023-04-28T17:08:15.667496Z",
     "shell.execute_reply": "2023-04-28T17:08:15.666329Z",
     "shell.execute_reply.started": "2023-04-28T17:07:51.770616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 24s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV9, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Ninth_Trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 84.27 %</br>\n",
    "**validatation accuracy (auc)**: 84.19 %</br>\n",
    "**Testing Accuracy (auc)**: 77.17 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "Here we tried more complex model as we used three layer from GNN layer.</br> \n",
    "But the accuracy decreased ten the simple model.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenth Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :**  Training data set without upsampling\n",
    "\n",
    "**The Model Used is :**\n",
    "The model uses a **single GNN layer** with hyperparameters configured to use a **Rational graph convolutional network** (RGCN) message passing method. The output of the GNN layer is passed through a function called **segment_mean**, which computes the mean of the node embeddings for each graph in the batch. This is intended to summarize the information from the nodes into a single vector per graph, which can be used for the prediction task.\n",
    "\n",
    "The output of the segment_mean function is passed through a **dense layer** with a **sigmoid** activation function to produce the final predictions. The model is compiled using the **binary cross-entropy loss** function and the **Adam optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T15:08:10.841148Z",
     "iopub.status.busy": "2023-04-25T15:08:10.839703Z",
     "iopub.status.idle": "2023-04-25T15:08:11.549886Z",
     "shell.execute_reply": "2023-04-25T15:08:11.548368Z",
     "shell.execute_reply.started": "2023-04-25T15:08:10.841077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_81 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_79 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_44 (TFOpLam  ()                  0           ['input_81[0][0]']               \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_25 (Embedding)       (None, 20)           10000       ['input_79[0][0]']               \n",
      "                                                                                                  \n",
      " input_80 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  ()                  0           ['tf.math.reduce_max_44[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_42 (GNN)                   (None, 64)           71552       ['embedding_25[0][0]',           \n",
      "                                                                  'input_80[0][0]',               \n",
      "                                                                  'input_81[0][0]',               \n",
      "                                                                  'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.segment_mean_11 (TFOpL  (None, 64)          0           ['gnn_42[0][0]',                 \n",
      " ambda)                                                           'input_81[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 1)            65          ['tf.math.segment_mean_11[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 81,617\n",
      "Trainable params: 81,617\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "# configure the hyperparameters of GNN layers\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "# \n",
    "# frist load the defualt hyperparameters\n",
    "params = GNN.get_default_hyperparameters()\n",
    "# sets the size of the output of all message passing layers\n",
    "params[\"hidden_dim\"] = 64\n",
    "# configures the message passing style to be RGCN\n",
    "params['message_calculation_class'] = 'RGCN'\n",
    "# configures the number of parallel (independent) weighted sums that are computed, whose results are concatenated to obtain the final result.\n",
    "params[\"num_heads\"] = 4\n",
    "\n",
    "# Implements a deep Graph Neural Network\n",
    "gnn_layer = GNN(params)\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "\n",
    "\n",
    "# Computes the mean along segments of a tensor\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "avg = segment_mean(\n",
    "    data = gnn_out,\n",
    "    segment_ids = node2graph\n",
    ")\n",
    "\n",
    "# Define the out put layer of the model\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "\n",
    "\n",
    "# Creating the model\n",
    "modelV10 = Model(\n",
    "    inputs = {\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs = pred\n",
    ")\n",
    "modelV10.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "modelV10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T15:08:15.411821Z",
     "iopub.status.busy": "2023-04-25T15:08:15.411375Z",
     "iopub.status.idle": "2023-04-25T15:30:17.861669Z",
     "shell.execute_reply": "2023-04-25T15:30:17.860376Z",
     "shell.execute_reply.started": "2023-04-25T15:08:15.411780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2530/2530 [==============================] - 70s 26ms/step - loss: 0.6142 - accuracy: 0.6621 - val_loss: 0.5911 - val_accuracy: 0.6894\n",
      "Epoch 2/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.5845 - accuracy: 0.6957 - val_loss: 0.5743 - val_accuracy: 0.7012\n",
      "Epoch 3/20\n",
      "2530/2530 [==============================] - 67s 27ms/step - loss: 0.5599 - accuracy: 0.7197 - val_loss: 0.5535 - val_accuracy: 0.7174\n",
      "Epoch 4/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.5319 - accuracy: 0.7401 - val_loss: 0.5182 - val_accuracy: 0.7533\n",
      "Epoch 5/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.5103 - accuracy: 0.7578 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 6/20\n",
      "2530/2530 [==============================] - 65s 26ms/step - loss: 0.4991 - accuracy: 0.7606 - val_loss: 0.4949 - val_accuracy: 0.7595\n",
      "Epoch 7/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.4769 - accuracy: 0.7745 - val_loss: 0.4746 - val_accuracy: 0.7771\n",
      "Epoch 8/20\n",
      "2530/2530 [==============================] - 65s 26ms/step - loss: 0.4591 - accuracy: 0.7858 - val_loss: 0.4653 - val_accuracy: 0.7880\n",
      "Epoch 9/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.4460 - accuracy: 0.7933 - val_loss: 0.4242 - val_accuracy: 0.8086\n",
      "Epoch 10/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.4264 - accuracy: 0.8062 - val_loss: 0.4116 - val_accuracy: 0.8073\n",
      "Epoch 11/20\n",
      "2530/2530 [==============================] - 65s 26ms/step - loss: 0.4101 - accuracy: 0.8146 - val_loss: 0.3947 - val_accuracy: 0.8269\n",
      "Epoch 12/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.3978 - accuracy: 0.8253 - val_loss: 0.3905 - val_accuracy: 0.8258\n",
      "Epoch 13/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.3837 - accuracy: 0.8286 - val_loss: 0.3626 - val_accuracy: 0.8447\n",
      "Epoch 14/20\n",
      "2530/2530 [==============================] - 64s 25ms/step - loss: 0.3754 - accuracy: 0.8344 - val_loss: 0.3668 - val_accuracy: 0.8447\n",
      "Epoch 15/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.3625 - accuracy: 0.8458 - val_loss: 0.3760 - val_accuracy: 0.8418\n",
      "Epoch 16/20\n",
      "2530/2530 [==============================] - 65s 26ms/step - loss: 0.3536 - accuracy: 0.8493 - val_loss: 0.3549 - val_accuracy: 0.8570\n",
      "Epoch 17/20\n",
      "2530/2530 [==============================] - 67s 26ms/step - loss: 0.3421 - accuracy: 0.8545 - val_loss: 0.3377 - val_accuracy: 0.8652\n",
      "Epoch 18/20\n",
      "2530/2530 [==============================] - 68s 27ms/step - loss: 0.3322 - accuracy: 0.8604 - val_loss: 0.3205 - val_accuracy: 0.8671\n",
      "Epoch 19/20\n",
      "2530/2530 [==============================] - 65s 26ms/step - loss: 0.3283 - accuracy: 0.8626 - val_loss: 0.3008 - val_accuracy: 0.8790\n",
      "Epoch 20/20\n",
      "2530/2530 [==============================] - 66s 26ms/step - loss: 0.3135 - accuracy: 0.8707 - val_loss: 0.3213 - val_accuracy: 0.8713\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV10, training_set, validation_set, batch_size=16, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T15:59:06.671428Z",
     "iopub.status.busy": "2023-04-25T15:59:06.670937Z",
     "iopub.status.idle": "2023-04-25T15:59:13.532115Z",
     "shell.execute_reply": "2023-04-25T15:59:13.530622Z",
     "shell.execute_reply.started": "2023-04-25T15:59:06.671387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 7s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV10, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Tenth_Trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 87.07 %</br>\n",
    "**validatation accuracy (auc)**: 87.13 %</br>\n",
    "**Testing Accuracy (auc)**: 50 %</br></br>\n",
    "\n",
    "**Comment :** </br>\n",
    "\n",
    "In previous trial we try to use the same model with the same massig passing method but here we will try to change in different hyperparameter as we see we will try to use 64 hidden_dim, and 4 num_heads. \n",
    "But the accuracy become so bad that may because of: </br>Lack of convergence: Changing the hyperparameters can affect the convergence of the model during training. If the model doesn't converge to a good solution, it may perform poorly on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elventh Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input of these trial is :** Upsampling training data set \n",
    "\n",
    "**The Model Used is :**\n",
    "\n",
    "**The model uses two GNN layers**, each with a different set of hyperparameters, to learn representations of the molecular graphs. The outputs of the GNN layers are then pooled **using mean pooling**, and **concatenated together**. The resulting pooled outputs are then passed through a **dropout layer** for regularization, and finally through **a dense layer** with a sigmoid activation function to produce the final predictions.\n",
    "\n",
    "**The model is compiled** using the AdamW optimizer and binary cross-entropy loss function, and the accuracy metric is used to evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T18:37:01.657581Z",
     "iopub.status.busy": "2023-04-28T18:37:01.657182Z",
     "iopub.status.idle": "2023-04-28T18:37:03.843274Z",
     "shell.execute_reply": "2023-04-28T18:37:03.841986Z",
     "shell.execute_reply.started": "2023-04-28T18:37:01.657547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_5 (TFOpLamb  ()                  0           ['input_13[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 20)           10000       ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  ()                  0           ['tf.math.reduce_max_5[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_7 (GNN)                    (None, 64)           71552       ['embedding_3[0][0]',            \n",
      "                                                                  'input_12[0][0]',               \n",
      "                                                                  'input_13[0][0]',               \n",
      "                                                                  'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " gnn_9 (GNN)                    (None, 32)           47808       ['embedding_3[0][0]',            \n",
      "                                                                  'input_12[0][0]',               \n",
      "                                                                  'input_13[0][0]',               \n",
      "                                                                  'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_mean_  (None, 64)          0           ['gnn_7[0][0]',                  \n",
      " 2 (TFOpLambda)                                                   'input_13[0][0]',               \n",
      "                                                                  'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_mean_  (None, 32)          0           ['gnn_9[0][0]',                  \n",
      " 3 (TFOpLambda)                                                   'input_13[0][0]',               \n",
      "                                                                  'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 96)           0           ['tf.math.unsorted_segment_mean_2\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'tf.math.unsorted_segment_mean_3\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 96)           0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            97          ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 129,457\n",
      "Trainable params: 129,457\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from tf2_gnn.utils.general import get_aggregate_method_from_str\n",
    "\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
    "gnn_input = GNNInput(\n",
    "    node_features = embeded,\n",
    "    adjacency_lists = (edge,),\n",
    "    node_to_graph_map = node2graph, \n",
    "    num_graphs = num_graph,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the GNN layers\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_heads\"] = 8\n",
    "params[\"dropout_rate\"] = 0.1\n",
    "params[\"message_calculation_class\"] = \"RGCN\"\n",
    "gnn_layer1 = GNN(params)\n",
    "gnn_out1 = gnn_layer1(gnn_input)\n",
    "\n",
    "params[\"hidden_dim\"] = 32\n",
    "params[\"num_heads\"] = 4\n",
    "params[\"dropout_rate\"] = 0.1\n",
    "params[\"message_calculation_class\"] = \"GGNN\"\n",
    "gnn_layer2 = GNN(params)\n",
    "gnn_out2 = gnn_layer2(gnn_input)\n",
    "\n",
    "gnn_layer2 = GNN(params)\n",
    "gnn_out2 = gnn_layer2(gnn_input)\n",
    "\n",
    "# Apply mean pooling to the outputs of the GNN layers\n",
    "pool_out1 = tf.math.unsorted_segment_mean(gnn_out1, node2graph, num_graph)\n",
    "pool_out2 = tf.math.unsorted_segment_mean(gnn_out2, node2graph, num_graph)\n",
    "\n",
    "# Concatenate the pooled outputs\n",
    "pool_out = layers.concatenate([pool_out1, pool_out2])\n",
    "\n",
    "# Add dropout regularization\n",
    "dropout = layers.Dropout(0.3)(pool_out)\n",
    "\n",
    "# Define the output layer of the model\n",
    "pred = layers.Dense(1, activation=\"sigmoid\")(dropout)\n",
    "\n",
    "# Create the model\n",
    "modelV11 = Model(inputs={\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },  outputs=pred)\n",
    "\n",
    "# Use AdamW optimizer and binary cross-entropy loss\n",
    "opt = Adam(learning_rate=0.001)\n",
    "modelV11.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "modelV11.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T06:15:08.672586Z",
     "iopub.status.busy": "2023-04-28T06:15:08.672015Z",
     "iopub.status.idle": "2023-04-28T06:43:31.837935Z",
     "shell.execute_reply": "2023-04-28T06:43:31.836633Z",
     "shell.execute_reply.started": "2023-04-28T06:15:08.672513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2530/2530 [==============================] - 95s 34ms/step - loss: 0.6227 - accuracy: 0.6569 - val_loss: 0.6194 - val_accuracy: 0.6448\n",
      "Epoch 2/20\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.5934 - accuracy: 0.6926 - val_loss: 0.5714 - val_accuracy: 0.7158\n",
      "Epoch 3/20\n",
      "2530/2530 [==============================] - 85s 33ms/step - loss: 0.5507 - accuracy: 0.7260 - val_loss: 0.5231 - val_accuracy: 0.7456\n",
      "Epoch 4/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.5046 - accuracy: 0.7634 - val_loss: 0.4882 - val_accuracy: 0.7695\n",
      "Epoch 5/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.4664 - accuracy: 0.7861 - val_loss: 0.4552 - val_accuracy: 0.7847\n",
      "Epoch 6/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.4353 - accuracy: 0.8022 - val_loss: 0.4124 - val_accuracy: 0.8124\n",
      "Epoch 7/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.4145 - accuracy: 0.8133 - val_loss: 0.3941 - val_accuracy: 0.8281\n",
      "Epoch 8/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.3889 - accuracy: 0.8274 - val_loss: 0.3899 - val_accuracy: 0.8338\n",
      "Epoch 9/20\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3780 - accuracy: 0.8346 - val_loss: 0.3915 - val_accuracy: 0.8285\n",
      "Epoch 10/20\n",
      "2530/2530 [==============================] - 87s 35ms/step - loss: 0.3663 - accuracy: 0.8406 - val_loss: 0.3690 - val_accuracy: 0.8447\n",
      "Epoch 11/20\n",
      "2530/2530 [==============================] - 86s 34ms/step - loss: 0.3501 - accuracy: 0.8473 - val_loss: 0.3252 - val_accuracy: 0.8625\n",
      "Epoch 12/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.3333 - accuracy: 0.8580 - val_loss: 0.3330 - val_accuracy: 0.8636\n",
      "Epoch 13/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.3206 - accuracy: 0.8646 - val_loss: 0.3044 - val_accuracy: 0.8803\n",
      "Epoch 14/20\n",
      "2530/2530 [==============================] - 85s 33ms/step - loss: 0.3140 - accuracy: 0.8692 - val_loss: 0.2991 - val_accuracy: 0.8818\n",
      "Epoch 15/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.3028 - accuracy: 0.8727 - val_loss: 0.2840 - val_accuracy: 0.8831\n",
      "Epoch 16/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.2938 - accuracy: 0.8782 - val_loss: 0.2789 - val_accuracy: 0.8891\n",
      "Epoch 17/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.2826 - accuracy: 0.8844 - val_loss: 0.2785 - val_accuracy: 0.8891\n",
      "Epoch 18/20\n",
      "2530/2530 [==============================] - 85s 34ms/step - loss: 0.2751 - accuracy: 0.8867 - val_loss: 0.2720 - val_accuracy: 0.8960\n",
      "Epoch 19/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.2690 - accuracy: 0.8896 - val_loss: 0.2619 - val_accuracy: 0.9037\n",
      "Epoch 20/20\n",
      "2530/2530 [==============================] - 84s 33ms/step - loss: 0.2618 - accuracy: 0.8943 - val_loss: 0.2654 - val_accuracy: 0.9002\n"
     ]
    }
   ],
   "source": [
    "train_model(modelV11, training_set, validation_set, batch_size=16, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T18:36:04.934071Z",
     "iopub.status.busy": "2023-04-28T18:36:04.932606Z",
     "iopub.status.idle": "2023-04-28T18:36:26.675744Z",
     "shell.execute_reply": "2023-04-28T18:36:26.674655Z",
     "shell.execute_reply.started": "2023-04-28T18:36:04.933943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 12s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_predictions(modelV11, testing_set)\n",
    "save_predictions_to_csv(y_pred, 'Eleventh_Trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the previous trial is :**  </br>\n",
    "**Training accuracy (auc)**: 89.43 %</br>\n",
    "**validatation accuracy (auc)**: 90.02 %</br>\n",
    "**Testing Accuracy (auc)**: 87.053 %</br></br>\n",
    "\n",
    "**Comment :** </br>  \n",
    "So these model get the best accuracy until now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model :\n",
    "From above we can see that the trial number eleven has the best scor in the test data set \n",
    "So we can achive our bst model by using : \n",
    "1. up sampling for the learning data set \n",
    "2. two GNN layer one of them use RGCN as  message calculation class ,and other GGNN\n",
    "3. mean pooling, and concatenated two layer \n",
    "4. dropout layer (0.3)\n",
    "5. finally, dense layer with sigmoid activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the provided template, describe the format of the input file (sdf file).**\n",
    "\n",
    "The Structure Data File (SDF) format is a text-based file format for storing molecular structures and associated data. It was originally developed by Molecular Design Limited (MDL) and is now widely used in the chemistry and drug discovery fields.\n",
    "\n",
    "The SDF format consists of a series of records, each of which represents a single molecular structure. Each record has a fixed format, consisting of one or more header lines followed by a series of data lines. The header lines describe the structure and associated data, while the data lines represent the atoms and bonds in the molecule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?**\n",
    "\n",
    "The input tensors to the neural network model are:\n",
    "\n",
    "**data tensor**: This tensor contains the node features for all the nodes in the input graph. It has a shape of **(batch_size, num_nodes)**, where batch_size is the number of graphs in the batch, and num_nodes is the maximum number of nodes in any graph in the batch. Each element in the tensor represents the feature value for a particular node in a particular graph.\n",
    "\n",
    "**edge tensor**: This tensor contains the edge connections between the nodes in the input graph. It is a **two-dimensional tensor** of shape **(num_edges, 2)**, where num_edges is the total number of edges in the batch. The first column represents the source node index, and the second column represents the destination node index.\n",
    "\n",
    "**node2graph tensor**: This tensor indicates which graph each node belongs to. It is a **one-dimensional** tensor of shape **(num_nodes,)**, where num_nodes is the total number of nodes in the batch. Each element in the tensor represents the graph ID of the corresponding node in the data tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?**\n",
    "\n",
    "**gnn_out**: This tensor represents the output of the GNN layers in the neural network model. It has a shape of (batch_size, num_nodes, hidden_dim), where:</br>\n",
    "\n",
    "*    batch_size is the number of graphs in the batch.</br>\n",
    "*    num_nodes is the maximum number of nodes in any graph in the batch.</br>\n",
    "*    hidden_dim is the number of hidden units in the GNN layers.</br>\n",
    " Each element of gnn_out represents the hidden state of a particular node in a particular graph, after processing the input graph through the GNN layers.</br></br>\n",
    "\n",
    "**avg**: This tensor represents the output of the global pooling operation on the gnn_out tensor. It has a shape of (batch_size, hidden_dim), where:\n",
    "\n",
    "*        batch_size is the number of graphs in the batch.</br>\n",
    "*        hidden_dim is the number of hidden units in the GNN layers.</br>\n",
    " Each element of avg represents the average hidden state across all nodes in a particular graph, after processing the input graph through the GNN layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?**\n",
    "\n",
    "**segment_mean** and **tf.reduce_mean** are two different functions in TensorFlow that compute the mean across different segments of a tensor.\n",
    "\n",
    "**tf.reduce_mean** computes the mean across all elements of a tensor, while **segment_mean** computes the mean across segments of a tensor, where the segments are defined by another tensor of the same shape.\n",
    "\n",
    "**For example,** if you have a tensor x of shape (batch_size, num_nodes, hidden_dim) and a tensor segment_ids of shape (batch_size, num_nodes), where each element of segment_ids represents the ID of the segment that the corresponding element of x belongs to, you can compute the segment means of x using segment_mean(x, segment_ids).\n",
    "\n",
    "**As for the dimensions of pred,** it depends on the task and the specific neural network model being used. In general, the dimensions of pred represent the output of the model after processing the input data, and can vary depending on the architecture of the model and the type of output being predicted.\n",
    "\n",
    "**However,** in the case of binary classification, pred typically has a shape of (batch_size, 1), where batch_size is the number of samples in the input batch, and each element represents the predicted probability that the corresponding sample belongs to the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?**\n",
    "\n",
    "The motivation behind using multiple graph convolutional network (GCN) layers in a neural network model is to enable the model to capture increasingly complex and abstract features of the input graph data. Each GCN layer learns to aggregate information from a node's local neighborhood, and the output of one GCN layer can be fed as input to the next GCN layer, allowing the model to learn more complex graph-level features that depend on larger neighborhoods of nodes.\n",
    "\n",
    "By stacking multiple GCN layers, the model can learn increasingly abstract representations of the input graph, allowing it to better distinguish between different types of graphs or perform more complex tasks on the graph data.\n",
    "\n",
    "The number of GCN layers used in a neural network model can vary depending on the specific application and the complexity of the input graph data. In the template provided, the model has two GCN layers, but this number can be increased or decreased depending on the needs of the specific application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
